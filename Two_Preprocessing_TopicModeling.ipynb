{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pycountry_convert as pc\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fairytales.csv')\n",
    "df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataframe into content and information of stories\n",
    "\n",
    "story = df.body\n",
    "story_info = df.drop('body', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Clever Thief</td>\n",
       "      <td>Hindu Tales from the Sanskrit</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Lac of Rupees for a Piece of Advice</td>\n",
       "      <td>Joseph Jacobs</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Leaf from the Sky</td>\n",
       "      <td>Hans Christian Andersen</td>\n",
       "      <td>Danish Nordic Scandinavian</td>\n",
       "      <td>Scandinavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Legend of Confucius</td>\n",
       "      <td>The Chinese Fairy Book</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Lesson for Kings</td>\n",
       "      <td>Joseph Jacobs</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title                         author  \\\n",
       "0                         A Clever Thief  Hindu Tales from the Sanskrit   \n",
       "1  A Lac of Rupees for a Piece of Advice                  Joseph Jacobs   \n",
       "2                    A Leaf from the Sky        Hans Christian Andersen   \n",
       "3                  A Legend of Confucius         The Chinese Fairy Book   \n",
       "4                     A Lesson for Kings                  Joseph Jacobs   \n",
       "\n",
       "                       region      country  \n",
       "0                      Indian        India  \n",
       "1                      Indian        India  \n",
       "2  Danish Nordic Scandinavian  Scandinavia  \n",
       "3                     Chinese        China  \n",
       "4                      Indian        India  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_info.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create continent column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website provides the regions of the fairy tales, and I need to convert regions to continents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nationality to country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this file to find corresponding country name of each fairy tale\n",
    "\n",
    "demonyms = pd.read_csv('demonyms.csv', header = None, names = ['nationality','country'])\n",
    "story_info = story_info.merge(demonyms.rename({'nationality': 'region'},axis=1),on = 'region', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_info.loc[(story_info.region == 'Native American North American'), 'country'] = 'North America'\n",
    "story_info.loc[(story_info.region == 'Canadian Native American North American'), 'country'] = 'North America'\n",
    "story_info.loc[(story_info.region == 'Native American'), 'country'] = 'North America'\n",
    "\n",
    "story_info.loc[(story_info.region == 'Danish Nordic Scandinavian'), 'country'] = 'Scandinavia'\n",
    "story_info.loc[(story_info.region == 'Nordic Scandinavian'), 'country'] = 'Scandinavia'\n",
    "story_info.loc[(story_info.region == 'Danish Scandinavian'), 'country'] = 'Scandinavia'\n",
    "story_info.loc[(story_info.region == 'Norwegian Scandinavian'), 'country'] = 'Scandinavia'\n",
    "story_info.loc[(story_info.region == 'Nordic Norwegian Scandinavian'), 'country'] = 'Scandinavia'\n",
    "story_info.loc[(story_info.region == 'English Nordic Scandinavian'), 'country'] = 'Scandinavia'\n",
    "\n",
    "story_info.loc[(story_info.region == 'Korean'), 'country'] = 'Korea'\n",
    "\n",
    "story_info.loc[(story_info.region == 'Catalan Spanish'), 'country'] = 'Spain'\n",
    "\n",
    "story_info.loc[(story_info.region == 'Czechoslovak Finnish'), 'country'] = 'Finland'\n",
    "\n",
    "story_info.loc[(story_info.region == 'Indian Pakistani'), 'country'] = 'Pakistan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Clever Thief</td>\n",
       "      <td>Hindu Tales from the Sanskrit</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Lac of Rupees for a Piece of Advice</td>\n",
       "      <td>Joseph Jacobs</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Leaf from the Sky</td>\n",
       "      <td>Hans Christian Andersen</td>\n",
       "      <td>Danish Nordic Scandinavian</td>\n",
       "      <td>Scandinavia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Legend of Confucius</td>\n",
       "      <td>The Chinese Fairy Book</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Lesson for Kings</td>\n",
       "      <td>Joseph Jacobs</td>\n",
       "      <td>Indian</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title                         author  \\\n",
       "0                         A Clever Thief  Hindu Tales from the Sanskrit   \n",
       "1  A Lac of Rupees for a Piece of Advice                  Joseph Jacobs   \n",
       "2                    A Leaf from the Sky        Hans Christian Andersen   \n",
       "3                  A Legend of Confucius         The Chinese Fairy Book   \n",
       "4                     A Lesson for Kings                  Joseph Jacobs   \n",
       "\n",
       "                       region      country  \n",
       "0                      Indian        India  \n",
       "1                      Indian        India  \n",
       "2  Danish Nordic Scandinavian  Scandinavia  \n",
       "3                     Chinese        China  \n",
       "4                      Indian        India  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_info.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country name to continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_continent(country_name):\n",
    "    \"\"\"\"\n",
    "    A function that converts country names to continent names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return country_continent_name\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_info['continent_name'] = story_info['country'].apply(lambda x: country_to_continent(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_info.loc[(story_info.country == 'North America'), 'continent_name'] = 'North America'\n",
    "story_info.loc[(story_info.country == 'Hawaii'), 'continent_name'] = 'North America'\n",
    "story_info.loc[(story_info.country == 'England'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Scotland'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Scandinavia'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Czechoslovakia'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Wales'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Cornwall'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.country == 'Africa'), 'continent_name'] = 'Africa'\n",
    "story_info.loc[(story_info.country == 'Rhodesia'), 'continent_name'] = 'Africa'\n",
    "story_info.loc[(story_info.country == 'Korea'), 'continent_name'] = 'Asia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_info.loc[(story_info.region == 'Arabic'), 'continent_name'] = 'Asia'  # mostly Asia\n",
    "story_info.loc[(story_info.region == 'Slavic'), 'continent_name'] = 'Europe'  # mostly Europe\n",
    "story_info.loc[(story_info.region == 'Nordic'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.region == 'Celtic'), 'continent_name'] = 'Asia'\n",
    "story_info.loc[(story_info.region == 'Sami'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.region == 'Maori'), 'continent_name'] = 'Oceania'\n",
    "story_info.loc[(story_info.region == 'Bukovinian'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.region == 'Danish Nordic'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.region == 'Serbian Slavic'), 'continent_name'] = 'Europe'\n",
    "story_info.loc[(story_info.region == 'Unknown'), 'continent_name'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europe           1919\n",
       "Asia              584\n",
       "North America     432\n",
       "Africa            110\n",
       "Oceania            60\n",
       "South America      31\n",
       "Unknown             4\n",
       "Name: continent_name, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_info.continent_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/all_story.pickle', 'wb') as to_write:\n",
    "    pickle.dump(story_all, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlp_pipeline:\n",
    "   \n",
    "\n",
    "    def __init__(self, vectorizer=CountVectorizer(), sp = None, model = None):\n",
    "        \"\"\"\n",
    "        A class for pipelining NLP cleaning and preprocessing. The user provides a series of \n",
    "        tools, and this class manages all of the training, transforming, and modification\n",
    "        of the text data.\n",
    "        ---\n",
    "        Inputs:\n",
    "        vectorizer: the model to use for vectorization of text data\n",
    "        sp: Spacy model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model = model\n",
    "        if not sp:\n",
    "            self.sp = spacy.load('en')\n",
    "        self.vectorizer = vectorizer\n",
    "        self._is_fit = False\n",
    "\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        A function to clean text: remove notes within text, numbers, punctuations, \n",
    "        get words to lower case and lemmatize the text.\n",
    "        It uses spaCy for text preprocessing.\n",
    "        \"\"\"\n",
    "\n",
    "        # remove the notes within text\n",
    "        remove_note = lambda x: re.sub('{.*}', ' ', x)\n",
    "\n",
    "        # remove numbers\n",
    "        alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "        # remove punctuation, get lower case\n",
    "        punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation),' ', x.lower())\n",
    "\n",
    "        # apply the lambda functions above\n",
    "        text = text.map(remove_note).map(alphanumeric).map(punc_lower)\n",
    "        \n",
    "        # lemmatize\n",
    "        clean_text = []\n",
    "        for indiv_text in text:\n",
    "            indiv_text = self.sp(indiv_text) # automatically tokenized\n",
    "            lemmatized = ' '.join([word.lemma_ for word in indiv_text])\n",
    "            lemmatized = re.sub('(-PRON-)', '', lemmatized)\n",
    "            clean_text.append(lemmatized) \n",
    "\n",
    "        \n",
    "        return clean_text\n",
    "    \n",
    "    \n",
    "    def fit(self, text):\n",
    "        \"\"\"\n",
    "        Cleans the data and then fits the vectorizer with\n",
    "        the user provided text\n",
    "        \"\"\"\n",
    "        clean_text = self.clean_text(text)\n",
    "        self.vectorizer.fit(clean_text)\n",
    "        self._is_fit = True\n",
    "              \n",
    "        \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"\n",
    "        Gets the feature names from the vectorizer.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self._is_fit:\n",
    "            raise ValueError(\"Must fit the models before getting feature names!\")\n",
    "        \n",
    "        return self.vectorizer.get_feature_names()\n",
    "    \n",
    "    def transform(self, text):\n",
    "        \"\"\"\n",
    "        Cleans any provided data and then transforms the data into\n",
    "        a vectorized format based on the fit function.\n",
    "        \"\"\"\n",
    "        if not self._is_fit:\n",
    "            raise ValueError(\"Must fit the models before transforming!\")\n",
    "        clean_text = self.clean_text(text)\n",
    "\n",
    "        return self.vectorizer.transform(clean_text)\n",
    "    \n",
    "    \n",
    "    def save_pipe(self, filename):\n",
    "        \"\"\"\n",
    "        Writes the attributes of the pipeline to a file\n",
    "        allowing a pipeline to be loaded later with the\n",
    "        pre-trained pieces in place.\n",
    "        \"\"\"\n",
    "        if type(filename) != str:\n",
    "            raise TypeError(\"filename must be a string\")\n",
    "        pickle.dump(self.__dict__, open(filename+\".mdl\", 'wb'))\n",
    "        \n",
    "        \n",
    "    def load_pipe(self, filename):\n",
    "        \"\"\"\n",
    "        Writes the attributes of the pipeline to a file\n",
    "        allowing a pipeline to be loaded later with the\n",
    "        pre-trained pieces in place.\n",
    "        \"\"\"\n",
    "        if type(filename) != str:\n",
    "            raise TypeError(\"filename must be a string\")\n",
    "        if filename[-4:] != '.mdl':\n",
    "            filename += '.mdl'\n",
    "        self.__dict__ = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text is cleaned every time I train the pipeline. Cleaning the text takes a really long time for my dataset, so I'm using the two individual functions below when I'm still trying different parameters for CV and TFIDF. After I decide on the parameters of CV or TFIDF, I can train the whole pipeline and save it for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load('en')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    A function to clean text: remove notes within text, numbers, punctuations, \n",
    "    get words to lower case and lemmatize the text.\n",
    "    It uses spaCy for text preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove the notes within text\n",
    "    remove_note = lambda x: re.sub('{.*}', ' ', x)\n",
    "    \n",
    "    # remove numbers\n",
    "    alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "    # remove punctuation, get lower case\n",
    "    punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation),' ', x.lower())\n",
    "\n",
    "    # apply the lambda functions above\n",
    "    text = text.map(remove_note).map(alphanumeric).map(punc_lower)\n",
    "\n",
    "    # lemmatize\n",
    "    clean_text = []\n",
    "    for indiv_text in text:\n",
    "        indiv_text = sp(indiv_text) # automatically tokenized\n",
    "        lemmatized = ' '.join([word.lemma_ for word in indiv_text])\n",
    "        lemmatized = re.sub('(-PRON-)', '', lemmatized)\n",
    "        clean_text.append(lemmatized) \n",
    "\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "def get_doc_term(vectorizer, doc):\n",
    "    \"\"\"\n",
    "    A function that returns the fitted vectorizer, the doc-term matrix and feature names.\n",
    "    \"\"\"\n",
    "    vec = vectorizer.fit(doc)\n",
    "    matrix = vec.transform(doc)\n",
    "    term = vec.get_feature_names()\n",
    "    return vec, matrix, term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_story = clean_text(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/clean_story.pickle', 'wb') as to_write:\n",
    "    pickle.dump(clean_story, to_write)\n",
    "with open('pickle_files/story_info.pickle', 'wb') as to_write:\n",
    "    pickle.dump(story_info, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell trains the pipeline.\n",
    "\n",
    "# cv1 = nlp_pipeline(CountVectorizer(ngram_range=(2,2), stop_words = 'english', min_df = 3))\n",
    "# cv1.fit(story)\n",
    "# cv1_matrix = cv1.transform(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1, cv1_matrix, cv1_terms = get_doc_term(CountVectorizer(ngram_range=(2,2), stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 118016)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2, cv2_matrix, cv2_terms = get_doc_term(CountVectorizer(ngram_range=(3,3),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 16770)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv3, cv3_matrix, cv3_terms = get_doc_term(CountVectorizer(ngram_range=(2,3),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 134786)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram  \n",
    "Setting min_df=3 can remove really rare words, especially words from other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1, tf1_matrix, tf1_terms = get_doc_term(TfidfVectorizer(ngram_range=(2,2),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 118016)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2, tf2_matrix, tf2_terms = get_doc_term(TfidfVectorizer(ngram_range=(3,3),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 16770)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram and trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf3, tf3_matrix, tf3_terms = get_doc_term(TfidfVectorizer(ngram_range=(2,3),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 134786)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf3_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram. Also set max_df = 20 to exclude most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf4, tf4_matrix, tf4_terms = get_doc_term(TfidfVectorizer(ngram_range=(2,2),stop_words = 'english', min_df = 3, max_df = 20), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 111868)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf4_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram. Try max_df = 10 too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf5, tf5_matrix, tf5_terms = get_doc_term(TfidfVectorizer(ngram_range=(2,2),stop_words = 'english', min_df = 3, max_df = 10), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 101287)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf5_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram and trigram. max_df = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf6, tf6_matrix, tf6_terms = get_doc_term(TfidfVectorizer(ngram_range=(2,3),stop_words = 'english', min_df = 3, max_df = 10), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 117396)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf6_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram. max_df = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf7, tf7_matrix, tf7_terms = get_doc_term(TfidfVectorizer(ngram_range=(1,1),stop_words = 'english', min_df = 3, max_df = 20), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 8941)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf7_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigram and bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf8, tf8_matrix, tf8_terms = get_doc_term(TfidfVectorizer(ngram_range=(1,2),stop_words = 'english', min_df = 3), clean_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140, 131774)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf8_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA is too slow. Use LDAMulticore instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_model(vectorizer, doc_term, num_topics, passes, text = story):\n",
    "    \"\"\"\n",
    "    A function for LDA topic modeling.\n",
    "    Inputs: pipeline of vectorizer, text, number of topics, number of passes\n",
    "    Output: LDA model and a list of generated topics.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_word = doc_term.transpose()\n",
    "    corpus = matutils.Sparse2Corpus(doc_word)\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    lda = models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=id2word, passes=passes)\n",
    "    topic_list = lda.print_topics()\n",
    "    return lda, topic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA\n",
    "\n",
    "Only using tfidf as recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    \"\"\"\n",
    "    Displays the top words in each topic.\n",
    "    \"\"\"\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSA_model(doc_term, num_topics):\n",
    "    \"\"\"\n",
    "    A function that trains LSA model. \n",
    "    Input: document-term matrix and number of topics.\n",
    "    Output: LSA model, document topic matrix, explained variance, topic term matrix.\n",
    "    \"\"\"\n",
    "    lsa = TruncatedSVD(num_topics)\n",
    "    doc_topic = lsa.fit_transform(doc_term)\n",
    "    variance = lsa.explained_variance_ratio_\n",
    "    topic_term = lsa.components_\n",
    "    return lsa, doc_topic, variance, topic_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son\n",
      "\n",
      "Topic  1\n",
      "old man, say old, old woman, war eagle, man old\n",
      "\n",
      "Topic  2\n",
      "old woman, little old, woman say, woman come, say old\n",
      "\n",
      "Topic  3\n",
      "ou jackalse, ou wolf, se ou, old woman, dat se\n",
      "\n",
      "Topic  4\n",
      "young man, say young, man tell, young woman, handsome young\n"
     ]
    }
   ],
   "source": [
    "lsa_tf1_1, doc_topic_tf1_1, variance_tf1_1, topic_term_tf1_1 = LSA_model(doc_term = tf1_matrix, num_topics = 5)\n",
    "display_topics(lsa_tf1_1, tf1.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son, say king, king daughter, man say\n",
      "\n",
      "Topic  1\n",
      "old man, say old, old woman, war eagle, man old, good old, man tell, mountain lion\n",
      "\n",
      "Topic  2\n",
      "old woman, little old, woman say, woman come, say old, poor old, woman sit, woman tell\n",
      "\n",
      "Topic  3\n",
      "ou jackalse, ou wolf, se ou, old woman, dat se, ou baviyàan, old hendrik, dis time\n",
      "\n",
      "Topic  4\n",
      "young man, say young, man tell, young woman, son king, handsome young, son law, white beaver\n",
      "\n",
      "Topic  5\n",
      "king son, say king, king daughter, old man, thou hast, say giant, thou art, thou wilt\n",
      "\n",
      "Topic  6\n",
      "st peter, peter say, young man, thou hast, say st, poor man, say lord, thou art\n",
      "\n",
      "Topic  7\n",
      "mr fox, mrs fox, king son, mr coyote, fox come, say mr, prairie dog, young man\n"
     ]
    }
   ],
   "source": [
    "lsa_tf1_2, doc_topic_tf1_2, variance_tf1_2, topic_term_tf1_2 = LSA_model(doc_term = tf1_matrix, num_topics = 8)\n",
    "display_topics(lsa_tf1_2, tf1.get_feature_names(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son, say king, king daughter, man say, long time, come home\n",
      "\n",
      "Topic  1\n",
      "old man, say old, old woman, war eagle, man old, good old, man tell, mountain lion, time old, man make\n",
      "\n",
      "Topic  2\n",
      "old woman, little old, woman say, woman come, say old, poor old, woman sit, woman tell, man old, woman beg\n",
      "\n",
      "Topic  3\n",
      "ou jackalse, ou wolf, se ou, old woman, dat se, old hendrik, ou baviyàan, dis time, yust dat, like dat\n",
      "\n",
      "Topic  4\n",
      "young man, say young, man tell, son law, young woman, son king, handsome young, ju ju, white beaver, snuff box\n",
      "\n",
      "Topic  5\n",
      "king son, king daughter, say king, old man, say giant, thou art, thou hast, thou wilt, son king, king say\n",
      "\n",
      "Topic  6\n",
      "st peter, peter say, young man, say st, say lord, thou hast, poor man, lord say, thou wilt, thou art\n",
      "\n",
      "Topic  7\n",
      "mr fox, king son, mrs fox, mr coyote, say mr, fox come, prairie dog, bold bold, poor mr, fox jump\n",
      "\n",
      "Topic  8\n",
      "thou hast, thou art, poor man, thou wilt, hast thou, dost thou, thou shalt, say thou, rich man, son chan\n",
      "\n",
      "Topic  9\n",
      "king son, little girl, ma ui, black fellow, little boy, say little, step mother, little hare, say mother, say giant\n"
     ]
    }
   ],
   "source": [
    "lsa_tf1_3, doc_topic_tf1_3, variance_tf1_3, topic_term_tf1_3 = LSA_model(doc_term = tf1_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf1_3, tf1.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son, say king, king daughter, man say, long time, come home, man come, king say, run away, come say, little girl\n",
      "\n",
      "Topic  1\n",
      "old man, say old, old woman, war eagle, man old, good old, man tell, mountain lion, time old, man make, tell old, duck people, man say, day old, bad old\n",
      "\n",
      "Topic  2\n",
      "old woman, little old, woman say, woman come, say old, poor old, woman sit, woman tell, man old, head cook, woman beg, woman little, woman look, woman live, woman ask\n",
      "\n",
      "Topic  3\n",
      "ou jackalse, ou wolf, se ou, old woman, dat se, old hendrik, ou baviyàan, dis time, yust dat, like dat, king lion, jackalse yust, darie ou, dat ou, se dat\n",
      "\n",
      "Topic  4\n",
      "young man, say young, man tell, ju ju, young woman, son law, handsome young, son king, white beaver, snuff box, man kill, man reply, tell young, bow arrow, man wife\n",
      "\n",
      "Topic  5\n",
      "king son, say king, king daughter, old man, say giant, thou hast, thou art, son king, thou wilt, king say, yellow lily, son say, say thou, thou shalt, giant daughter\n",
      "\n",
      "Topic  6\n",
      "st peter, peter say, young man, say st, say lord, poor man, thou hast, lord say, thou wilt, thou art, shoemaker say, lord st, rich man, thou shalt, heaven day\n",
      "\n",
      "Topic  7\n",
      "mr fox, mrs fox, king son, mr coyote, fox come, say mr, prairie dog, young man, bold bold, poor mr, fox say, fox jump, say fox, st peter, old mr\n",
      "\n",
      "Topic  8\n",
      "thou hast, thou art, poor man, thou wilt, hast thou, thou shalt, dost thou, say thou, rich man, son chan, thee thou, rich brother, young man, art thou, thou dost\n",
      "\n",
      "Topic  9\n",
      "king son, little girl, little boy, mrs brien, black fellow, say little, say mother, say giant, good people, step mother, say man, young woman, ju ju, giant daughter, little bird\n",
      "\n",
      "Topic  10\n",
      "poor man, rich man, rich brother, poor brother, say man, say fin, ma ui, say poor, say king, man come, wife child, say wife, ju ju, man say, king son\n",
      "\n",
      "Topic  11\n",
      "bonne biche, beau minon, poor man, little girl, rich man, biche beau, king son, dear blondine, step mother, say blondine, forest lilacs, rich brother, ju ju, apple tree, snow white\n",
      "\n",
      "Topic  12\n",
      "black fellow, bonne biche, beau minon, little bird, biche beau, drive spear, eagle hawk, spear black, fellow live, little brother, dear blondine, dead emu, little dog, wife child, say blondine\n",
      "\n",
      "Topic  13\n",
      "ma ui, bonne biche, beau minon, say fin, king daughter, blind man, potato face, biche beau, little man, say king, face blind, ui make, fish hook, dear blondine, say blondine\n",
      "\n",
      "Topic  14\n",
      "dweller asgard, bonne biche, beau minon, say loki, say fin, say thor, blind man, say giant, little man, potato face, thor loki, loki say, æsir vanir, thor say, rainbow bridge\n"
     ]
    }
   ],
   "source": [
    "################  The best LSA Model  ################\n",
    "\n",
    "lsa_tf1_4, doc_topic_tf1_4, variance_tf1_4, topic_term_tf1_4 = LSA_model(doc_term = tf1_matrix, num_topics = 15)\n",
    "display_topics(lsa_tf1_4, tf1.get_feature_names(), 15)\n",
    "\n",
    "# Identify topics:\n",
    "# 0:human kingdom; 1: people&animals; 2: poverty; 3:people&animals; 4: war; 5.kingdom; 6: religion; 7: animal characters;\n",
    "# 8: rich vs. poor; 9: family; 10: rich vs. poor; 11: rich vs. poor; 12: people&animals; 13: kingdom; 14:norse mythology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_model = [lsa_tf1_4, doc_topic_tf1_4, variance_tf1_4, topic_term_tf1_4]\n",
    "\n",
    "with open('pickle_files/lsa_bestmodel.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lsa_model, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/lsa_doc_term.pickle', 'wb') as to_write:\n",
    "    pickle.dump(tf1_matrix, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_files/tfidf.pickle', 'wb') as to_write:\n",
    "    pickle.dump(tf1, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "say old man, old man say, say old woman, little old woman, old woman say\n",
      "\n",
      "Topic  1\n",
      "little old woman, old woman come, say little old, old woman say, monkey think trick\n",
      "\n",
      "Topic  2\n",
      "se ou jackalse, se ou wolf, ou jackalse yust, ou jackalse dat, ou jackalse ou\n",
      "\n",
      "Topic  3\n",
      "face blind man, potato face blind, little old woman, say potato face, village liver onion\n",
      "\n",
      "Topic  4\n",
      "say old man, little old woman, old man say, old man tell, old man come\n"
     ]
    }
   ],
   "source": [
    "lsa_tf2_1, doc_topic_tf2_1, variance_tf2_1, topic_term_tf2_1 = LSA_model(doc_term = tf2_matrix, num_topics = 5)\n",
    "display_topics(lsa_tf2_1, tf2.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "say old man, old man say, say old woman, little old woman, old woman say, old man tell, old man come, old woman come\n",
      "\n",
      "Topic  1\n",
      "little old woman, say little old, old woman come, monkey think trick, old woman say, old woman make, old woman stand, old woman angry\n",
      "\n",
      "Topic  2\n",
      "se ou jackalse, se ou wolf, ou jackalse yust, ou jackalse dat, ou jackalse ou, dat se ou, darie ou jackalse, ou wolf dat\n",
      "\n",
      "Topic  3\n",
      "potato face blind, face blind man, little old woman, say potato face, village liver onion, near post office, corner near post, blind man sit\n",
      "\n",
      "Topic  4\n",
      "say old man, little old woman, old man say, old man tell, old man come, old man make, tell old man, time old man\n",
      "\n",
      "Topic  5\n",
      "draw nigh unto, thou hast spoken, spoken word ssarwala, sack air ssidi, hast spoken word, burst sack air, word ssarwala missdood, destiny thou hast\n",
      "\n",
      "Topic  6\n",
      "say old woman, old woman say, old man daughter, old woman come, say old man, old man old, poor old woman, old woman daughter\n",
      "\n",
      "Topic  7\n",
      "ha ha ha, ha ha laugh, say old woman, long long ago, open mouth wide, yes yes say, shall die come, rip van winkle\n"
     ]
    }
   ],
   "source": [
    "lsa_tf2_2, doc_topic_tf2_2, variance_tf2_2, topic_term_tf2_2 = LSA_model(doc_term = tf2_matrix, num_topics = 8)\n",
    "display_topics(lsa_tf2_2, tf2.get_feature_names(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "say old man, old man say, say old woman, little old woman, old woman say, old man tell, old man come, old woman come, old man old, say young man\n",
      "\n",
      "Topic  1\n",
      "little old woman, old woman come, say little old, old woman say, monkey think trick, old woman make, old woman stand, old woman angry, old woman know, hard hard blow\n",
      "\n",
      "Topic  2\n",
      "se ou jackalse, se ou wolf, ou jackalse yust, ou jackalse dat, ou jackalse ou, dat se ou, darie ou jackalse, ou wolf dat, dat ou wolf, se se ou\n",
      "\n",
      "Topic  3\n",
      "face blind man, potato face blind, little old woman, say potato face, village liver onion, corner near post, near post office, blind man sit, ask potato face, blind man begin\n",
      "\n",
      "Topic  4\n",
      "say old man, little old woman, old man say, old man tell, old man come, old man make, tell old man, time old man, ask old man, old man begin\n",
      "\n",
      "Topic  5\n",
      "draw nigh unto, thou hast spoken, spoken word ssarwala, sack air ssidi, hast spoken word, burst sack air, word ssarwala missdood, ruler destiny thou, destiny thou hast, son chan ruler\n",
      "\n",
      "Topic  6\n",
      "ha ha ha, ha ha laugh, long long ago, say king son, happy hunting ground, mount horse ride, large sum money, long time ago, make sign cross, say little man\n",
      "\n",
      "Topic  7\n",
      "ha ha ha, ha ha laugh, say old woman, oo oo oo, old man daughter, long long ago, open mouth wide, poor old woman, yes yes say, wait long time\n",
      "\n",
      "Topic  8\n",
      "say king son, king son say, say old man, king son come, ha ha ha, king son marry, son say giant, son king erin, say thou hast, ask king son\n",
      "\n",
      "Topic  9\n",
      "village cream puff, milo winter publish, illustration milo winter, winter publish aesop, winter rand mcnally, publish aesop child, child picture milo, milo winter rand, picture milo winter, aesop child picture\n"
     ]
    }
   ],
   "source": [
    "lsa_tf2_3, doc_topic_tf2_3, variance_tf2_3, topic_term_tf2_3 = LSA_model(doc_term = tf2_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf2_3, tf2.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son\n",
      "\n",
      "Topic  1\n",
      "old man, say old man, say old, old man say, war eagle\n",
      "\n",
      "Topic  2\n",
      "ou jackalse, ou wolf, se ou, se ou jackalse, se ou wolf\n",
      "\n",
      "Topic  3\n",
      "old woman, ou jackalse, ou wolf, se ou, say old woman\n",
      "\n",
      "Topic  4\n",
      "young man, say young man, say young, young man say, young man tell\n"
     ]
    }
   ],
   "source": [
    "lsa_tf3_1, doc_topic_tf3_1, variance_tf3_1, topic_term_tf3_1 = LSA_model(doc_term = tf3_matrix, num_topics = 5)\n",
    "display_topics(lsa_tf3_1, tf3.get_feature_names(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son, say king, king daughter, man say\n",
      "\n",
      "Topic  1\n",
      "old man, say old man, say old, old man say, war eagle, old woman, old man tell, man old\n",
      "\n",
      "Topic  2\n",
      "ou jackalse, ou wolf, se ou, se ou jackalse, se ou wolf, old man, dat se, old hendrik\n",
      "\n",
      "Topic  3\n",
      "old woman, ou jackalse, ou wolf, se ou, say old woman, little old woman, old woman say, se ou jackalse\n",
      "\n",
      "Topic  4\n",
      "young man, say young man, say young, young man say, young man tell, young man come, ju ju, son law\n",
      "\n",
      "Topic  5\n",
      "king son, say king, king daughter, say king son, old man, say giant, young man, son king\n",
      "\n",
      "Topic  6\n",
      "st peter, st peter say, peter say, young man, say st peter, say st, say lord, king son\n",
      "\n",
      "Topic  7\n",
      "mr fox, king son, mrs fox, mr coyote, say mr fox, young man, say mr, mr fox come\n"
     ]
    }
   ],
   "source": [
    "lsa_tf3_2, doc_topic_tf3_2, variance_tf3_2, topic_term_tf3_2 = LSA_model(doc_term = tf3_matrix, num_topics = 8)\n",
    "display_topics(lsa_tf3_2, tf3.get_feature_names(), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "old man, old woman, young man, say old, king son, say king, king daughter, man say, long time, come home\n",
      "\n",
      "Topic  1\n",
      "old man, say old man, say old, old man say, war eagle, old woman, old man tell, man old, old man come, old man old\n",
      "\n",
      "Topic  2\n",
      "ou jackalse, ou wolf, se ou, se ou jackalse, se ou wolf, old man, dat se, old hendrik, ou baviyàan, dis time\n",
      "\n",
      "Topic  3\n",
      "old woman, ou jackalse, ou wolf, se ou, say old woman, little old woman, old woman say, se ou jackalse, little old, woman say\n",
      "\n",
      "Topic  4\n",
      "young man, say young man, say young, young man say, young man tell, young man come, man tell, young man reply, handsome young, young woman\n",
      "\n",
      "Topic  5\n",
      "king son, say king, king daughter, say king son, old man, say giant, thou hast, thou art, young man, son king\n",
      "\n",
      "Topic  6\n",
      "st peter, st peter say, peter say, young man, say st peter, say st, say lord, thou hast, lord say, poor man\n",
      "\n",
      "Topic  7\n",
      "mr fox, mrs fox, mr coyote, king son, say mr fox, say mr, fox come, mr fox come, prairie dog, young man\n",
      "\n",
      "Topic  8\n",
      "thou hast, poor man, thou art, thou wilt, rich man, hast thou, son chan, thou shalt, say thou, dost thou\n",
      "\n",
      "Topic  9\n",
      "king son, little girl, little boy, say king son, black fellow, poor man, say little, say mother, say giant, rich man\n"
     ]
    }
   ],
   "source": [
    "lsa_tf3_3, doc_topic_tf3_3, variance_tf3_3, topic_term_tf3_1 = LSA_model(doc_term = tf3_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf3_3, tf3.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "ou jackalse, ou wolf, se ou, dat se, old hendrik, ou baviyàan, dis time, yust dat, king lion, like dat\n",
      "\n",
      "Topic  1\n",
      "mr fox, mrs brien, black fellow, say fin, prince ivan, man eater, charcoal burner, ju ju, rich brother, wild man\n",
      "\n",
      "Topic  2\n",
      "mr fox, mrs fox, mr coyote, prairie dog, bold bold, poor mr, fox jump, dance hard, old mr, soon mr\n",
      "\n",
      "Topic  3\n",
      "black fellow, eagle hawk, drive spear, fellow live, spear black, dead emu, place black, piece bark, sit bush, dog bite\n",
      "\n",
      "Topic  4\n",
      "bonne biche, beau minon, biche beau, dear blondine, say blondine, forest lilacs, say fin, blondine say, blondine know, blondine enter\n",
      "\n",
      "Topic  5\n",
      "ma ui, bonne biche, son chan, beau minon, wife chan, ui make, fish hook, prince ivan, say unto, lift sky\n",
      "\n",
      "Topic  6\n",
      "son chan, wife chan, say fin, say unto, chan say, draw nigh, nigh unto, fenians erin, mrs brien, fin maccumhail\n",
      "\n",
      "Topic  7\n",
      "ju ju, say fin, fenians erin, fin maccumhail, ju man, water ju, raja rasâlu, man eater, fin say, fin man\n",
      "\n",
      "Topic  8\n",
      "ju ju, ju man, water ju, old peter, son chan, potato face, herr gabriel, face blind, slave girl, singing master\n",
      "\n",
      "Topic  9\n",
      "say loki, say thor, ju ju, thor loki, loki say, thor say, æsir vanir, rainbow bridge, odin father, say odin\n"
     ]
    }
   ],
   "source": [
    "lsa_tf4_1, doc_topic_tf4_1, variance_tf4_1, topic_term_tf4_1 = LSA_model(doc_term = tf4_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf4_1, tf4.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "ou jackalse, ou wolf, ou baviyàan, jackalse yust, king lion, darie ou, dat ou, se dat, look ou, den ou\n",
      "\n",
      "Topic  1\n",
      "say fin, prince ivan, bonne biche, golden horse, ma ui, beau minon, glass mountain, fenians erin, white bear, fin maccumhail\n",
      "\n",
      "Topic  2\n",
      "bonne biche, beau minon, biche beau, dear blondine, say blondine, forest lilacs, blondine say, blondine know, blondine enter, evil genius\n",
      "\n",
      "Topic  3\n",
      "ma ui, ui make, fish hook, lift sky, ui say, let line, great island, ui let, say ma, sacred bird\n",
      "\n",
      "Topic  4\n",
      "say fin, fenians erin, fin maccumhail, fin say, fin man, chew thumb, ask fin, conan maol, fin castle, come fin\n",
      "\n",
      "Topic  5\n",
      "mr coyote, prairie dog, water jar, little hen, end stick, fruit water, note san, hopi mesa, note hopi, home river\n",
      "\n",
      "Topic  6\n",
      "father horrigan, say dermod, dermod leary, save day, fairy scamper, priest supper, fine salmon, civil question, hear priest, horrigan tell\n",
      "\n",
      "Topic  7\n",
      "prince ivan, little hen, little cock, mrs fox, linden tree, rise red, baba yaga, spring drop, iron tooth, sun little\n",
      "\n",
      "Topic  8\n",
      "herr gabriel, little hen, singing master, golden horse, mother grandmother, golden maiden, little cock, madame gabriel, madam court, say peer\n",
      "\n",
      "Topic  9\n",
      "prince ivan, ivan tsarevich, herr gabriel, tsarevich ivan, singing master, mother grandmother, ox ox, madame gabriel, baba yaga, quench burn\n"
     ]
    }
   ],
   "source": [
    "lsa_tf5_1, doc_topic_tf5_1, variance_tf5_1, topic_term_tf5_1 = LSA_model(doc_term = tf5_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf5_1, tf5.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "ou jackalse, ou wolf, se ou jackalse, se ou wolf, ou baviyàan, king lion, ou jackalse yust, jackalse yust, darie ou, se dat\n",
      "\n",
      "Topic  1\n",
      "say fin, prince ivan, bonne biche, ma ui, beau minon, glass mountain, fenians erin, golden horse, fin maccumhail, ivan tsarevich\n",
      "\n",
      "Topic  2\n",
      "bonne biche, beau minon, bonne biche beau, biche beau, biche beau minon, dear blondine, say blondine, forest lilacs, blondine say, blondine know\n",
      "\n",
      "Topic  3\n",
      "ma ui, ui make, ma ui make, fish hook, lift sky, ma ui say, ui say, let line, great island, ui let\n",
      "\n",
      "Topic  4\n",
      "say fin, fenians erin, fin maccumhail, fin say, fin man, chew thumb, ask fin, conan maol, fin castle, come fin\n",
      "\n",
      "Topic  5\n",
      "mr coyote, father horrigan, prairie dog, say dermod, say father horrigan, water jar, ivan tsarevich, dermod leary, mrs fox, save day\n",
      "\n",
      "Topic  6\n",
      "father horrigan, say dermod, say father horrigan, dermod leary, save day, fairy scamper, priest supper, fine salmon, civil question, hear priest\n",
      "\n",
      "Topic  7\n",
      "raja rasâlu, play chaupur, king sarkap, play chaupur king, chaupur king, raja sarkap, headless corpse, shine armour, potato face blind, face blind man\n",
      "\n",
      "Topic  8\n",
      "prince ivan, ivan tsarevich, tsarevich ivan, baba yaga, raja rasâlu, little hen, play chaupur, wife chan, king sarkap, play chaupur king\n",
      "\n",
      "Topic  9\n",
      "face blind man, potato face blind, little hen, milo winter, herr gabriel, singing master, little cock, mother grandmother, publish aesop, raja rasâlu\n"
     ]
    }
   ],
   "source": [
    "lsa_tf6_1, doc_topic_tf6_1, variance_tf6_1, topic_term_tf6_1 = LSA_model(doc_term = tf6_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf6_1, tf6.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "coyote, iktomi, antler, slime, gum, bunny, skate, curlew, taos, mesa\n",
      "\n",
      "Topic  1\n",
      "dat, ou, se, jackalse, yust, dere, ole, wid, dey, dis\n",
      "\n",
      "Topic  2\n",
      "chan, ssidi, tângâri, ssarwala, pincer, carver, spoken, pagoda, missdood, jakzang\n",
      "\n",
      "Topic  3\n",
      "violette, ourson, agnella, passerose, drolette, aimee, venom, superintendent, nonchalante, indolent\n",
      "\n",
      "Topic  4\n",
      "tsarevich, tsarevna, squire, heifer, tsarina, ju, sigurd, pood, kirtle, tsaritsa\n",
      "\n",
      "Topic  5\n",
      "perseus, gorgon, medusa, andromeda, danaë, argos, athené, sigurd, polydecte, argo\n",
      "\n",
      "Topic  6\n",
      "sigurd, brynhild, fafnir, gunnar, regin, sigmund, grani, gudrun, volsung, blondine\n",
      "\n",
      "Topic  7\n",
      "blondine, biche, bonne, minon, beau, gourmandinet, lilacs, brunette, benin, fourbette\n",
      "\n",
      "Topic  8\n",
      "ju, calabar, foo, alligator, iktomi, effiong, hedgehog, eyo, outa, palaver\n",
      "\n",
      "Topic  9\n",
      "raja, rasâlu, sarkap, brahman, vizier, fakir, jôgi, rupee, chaupur, sâlbâhan\n"
     ]
    }
   ],
   "source": [
    "lsa_tf7_1, doc_topic_tf7_1, variance_tf7_1, topic_term_tf7_1 = LSA_model(doc_term = tf7_matrix, num_topics = 10)\n",
    "display_topics(lsa_tf7_1, tf7.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDAMulticore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDAMulticore_model(vectorizer, doc_term, num_topics, passes, chunksize, workers, text = story):\n",
    "    \"\"\"\n",
    "    A function for LDA topic modeling.\n",
    "    Inputs: vectorizer, document-term matrix,, number of topics, number of passes, chucksize, number of workers.\n",
    "    Output: LDA model and a list of generated topics.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_word = doc_term.transpose()\n",
    "    corpus = matutils.Sparse2Corpus(doc_word)\n",
    "    id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "    ldaMulticore = models.LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=id2word, \n",
    "                                       passes=passes, chunksize = chunksize, workers = workers)\n",
    "    topic_list = ldaMulticore.print_topics()\n",
    "    return ldaMulticore, topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb41b8fd0>,\n",
       " [(0,\n",
       "   '0.000*\"old woman\" + 0.000*\"bush rat\" + 0.000*\"main street\" + 0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"food cow\" + 0.000*\"little lamb\" + 0.000*\"yellow dog\" + 0.000*\"great spirit\"'),\n",
       "  (1,\n",
       "   '0.001*\"old man\" + 0.001*\"old woman\" + 0.000*\"young man\" + 0.000*\"long time\" + 0.000*\"say king\" + 0.000*\"run away\" + 0.000*\"little house\" + 0.000*\"water demon\" + 0.000*\"king daughter\" + 0.000*\"little boy\"'),\n",
       "  (2,\n",
       "   '0.001*\"old man\" + 0.000*\"hoo hoo\" + 0.000*\"say musician\" + 0.000*\"birch tree\" + 0.000*\"head servant\" + 0.000*\"mountain lion\" + 0.000*\"bend break\" + 0.000*\"lady moon\" + 0.000*\"war eagle\" + 0.000*\"little brother\"'),\n",
       "  (3,\n",
       "   '0.001*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.001*\"se ou\" + 0.000*\"little hahsie\" + 0.000*\"old man\" + 0.000*\"king lion\" + 0.000*\"white feather\" + 0.000*\"old hendrik\" + 0.000*\"ou sculpat\" + 0.000*\"sea serpent\"'),\n",
       "  (4,\n",
       "   '0.000*\"oo oo\" + 0.000*\"oom jakhal\" + 0.000*\"little bird\" + 0.000*\"time cat\" + 0.000*\"make axe\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"wood chopper\" + 0.000*\"brown sister\"')])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_1, ldaMulticore_tf1_1_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 5, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_1, ldaMulticore_tf1_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c44793290>,\n",
       " [(0,\n",
       "   '0.001*\"make sign cross\" + 0.000*\"old man leave\" + 0.000*\"ragnarök twilight god\" + 0.000*\"say old man\" + 0.000*\"exclaim foolish creature\" + 0.000*\"bear touch dead\" + 0.000*\"long time ago\" + 0.000*\"earth open eye\" + 0.000*\"year ago live\" + 0.000*\"tell wonderful story\"'),\n",
       "  (1,\n",
       "   '0.001*\"little old woman\" + 0.001*\"say old woman\" + 0.001*\"say old man\" + 0.001*\"old woman say\" + 0.001*\"say king son\" + 0.001*\"old woman come\" + 0.001*\"little old man\" + 0.001*\"old man say\" + 0.001*\"say young man\" + 0.001*\"great deal money\"'),\n",
       "  (2,\n",
       "   '0.001*\"say old man\" + 0.001*\"se ou jackalse\" + 0.001*\"old man say\" + 0.001*\"long long ago\" + 0.001*\"old man tell\" + 0.001*\"se ou wolf\" + 0.001*\"say old woman\" + 0.001*\"time old man\" + 0.001*\"old man make\" + 0.001*\"tell old man\"'),\n",
       "  (3,\n",
       "   '0.001*\"village cream puff\" + 0.001*\"fling open door\" + 0.001*\"happy hunting ground\" + 0.001*\"long time ago\" + 0.001*\"mount horse ride\" + 0.001*\"gold buckskin whincher\" + 0.001*\"way way ham\" + 0.000*\"way ham yoh\" + 0.000*\"fly branch tree\" + 0.000*\"learn magic art\"'),\n",
       "  (4,\n",
       "   '0.001*\"die broken heart\" + 0.001*\"say old man\" + 0.000*\"little old woman\" + 0.000*\"old woman say\" + 0.000*\"large sum money\" + 0.000*\"say thou art\" + 0.000*\"say poor man\" + 0.000*\"potato face blind\" + 0.000*\"face blind man\" + 0.000*\"old woman come\"')])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf2_1, ldaMulticore_tf2_1_topics = LDAMulticore_model(vectorizer = tf2, doc_term = tf2_matrix, \n",
    "                                                               num_topics = 5, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf2_1, ldaMulticore_tf2_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bdbbb1450>,\n",
       " [(0,\n",
       "   '0.001*\"old man\" + 0.001*\"old woman\" + 0.000*\"young man\" + 0.000*\"long time\" + 0.000*\"say king\" + 0.000*\"hoo hoo\" + 0.000*\"water demon\" + 0.000*\"king daughter\" + 0.000*\"yellow lily\" + 0.000*\"poor man\"'),\n",
       "  (1,\n",
       "   '0.001*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.000*\"se ou\" + 0.000*\"little hahsie\" + 0.000*\"se ou jackalse\" + 0.000*\"white feather\" + 0.000*\"king lion\" + 0.000*\"ou sculpat\" + 0.000*\"old hendrik\" + 0.000*\"se hahsie\"'),\n",
       "  (2,\n",
       "   '0.001*\"old man\" + 0.000*\"war eagle\" + 0.000*\"birch tree\" + 0.000*\"mountain lion\" + 0.000*\"black fellow\" + 0.000*\"white corn\" + 0.000*\"bend break\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"yellow dog\"'),\n",
       "  (3,\n",
       "   '0.000*\"bush rat\" + 0.000*\"young man\" + 0.000*\"big brother\" + 0.000*\"little bird\" + 0.000*\"old farmer\" + 0.000*\"golden haired\" + 0.000*\"thou lt\" + 0.000*\"dead body\" + 0.000*\"beautiful field\" + 0.000*\"little brother\"'),\n",
       "  (4,\n",
       "   '0.000*\"old woman\" + 0.000*\"main street\" + 0.000*\"great spirit\" + 0.000*\"oo oo\" + 0.000*\"little lamb\" + 0.000*\"lady moon\" + 0.000*\"oom jakhal\" + 0.000*\"ruler heaven\" + 0.000*\"little boy\" + 0.000*\"overtake throw\"')])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf3_1, ldaMulticore_tf3_1_topics = LDAMulticore_model(vectorizer = tf3, doc_term = tf3_matrix, \n",
    "                                                               num_topics = 5, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf3_1, ldaMulticore_tf3_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb217add0>,\n",
       " [(0,\n",
       "   '0.001*\"yellow lily\" + 0.000*\"old man\" + 0.000*\"white corn\" + 0.000*\"say musician\" + 0.000*\"grandmother spider\" + 0.000*\"rich brother\" + 0.000*\"thou lt\" + 0.000*\"say peasant\" + 0.000*\"ruler heaven\" + 0.000*\"time cat\"'),\n",
       "  (1,\n",
       "   '0.002*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.001*\"se ou\" + 0.000*\"black fellow\" + 0.000*\"young man\" + 0.000*\"old man\" + 0.000*\"little bird\" + 0.000*\"head servant\" + 0.000*\"year ago\" + 0.000*\"thou art\"'),\n",
       "  (2,\n",
       "   '0.001*\"water demon\" + 0.000*\"old man\" + 0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"yellow dog\" + 0.000*\"mrs brien\" + 0.000*\"little brother\" + 0.000*\"christmas eve\" + 0.000*\"golden basin\"'),\n",
       "  (3,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"little lamb\" + 0.000*\"se ole\" + 0.000*\"animal bird\" + 0.000*\"dat honey\" + 0.000*\"left foot\" + 0.000*\"pull sea\" + 0.000*\"honey se\" + 0.000*\"gum tree\" + 0.000*\"kill eat\"'),\n",
       "  (4,\n",
       "   '0.001*\"old man\" + 0.001*\"old woman\" + 0.001*\"young man\" + 0.000*\"say king\" + 0.000*\"long time\" + 0.000*\"run away\" + 0.000*\"bush rat\" + 0.000*\"king son\" + 0.000*\"king say\" + 0.000*\"king daughter\"'),\n",
       "  (5,\n",
       "   '0.000*\"old farmer\" + 0.000*\"old man\" + 0.000*\"golden ducat\" + 0.000*\"great spirit\" + 0.000*\"pride joy\" + 0.000*\"make axe\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"wood chopper\"'),\n",
       "  (6,\n",
       "   '0.001*\"brown sister\" + 0.000*\"white feather\" + 0.000*\"young man\" + 0.000*\"little house\" + 0.000*\"king lion\" + 0.000*\"yum yum\" + 0.000*\"old dragon\" + 0.000*\"pocket handkerchief\" + 0.000*\"little hahsie\" + 0.000*\"croak frog\"'),\n",
       "  (7,\n",
       "   '0.000*\"main street\" + 0.000*\"ou sculpat\" + 0.000*\"birch tree\" + 0.000*\"little hahsie\" + 0.000*\"big brother\" + 0.000*\"lady moon\" + 0.000*\"bend break\" + 0.000*\"old woman\" + 0.000*\"say moon\" + 0.000*\"little brother\"')])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_2, ldaMulticore_tf1_2_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_2, ldaMulticore_tf1_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c18a29990>,\n",
       " [(0,\n",
       "   '0.001*\"fling open door\" + 0.001*\"ragnarök twilight god\" + 0.001*\"head rest hand\" + 0.001*\"little bird say\" + 0.001*\"long long ago\" + 0.001*\"mr fox come\" + 0.000*\"think good way\" + 0.000*\"word come blow\" + 0.000*\"open door let\" + 0.000*\"morning poor man\"'),\n",
       "  (1,\n",
       "   '0.001*\"die broken heart\" + 0.001*\"cow cow milk\" + 0.001*\"tell young woman\" + 0.001*\"say mrs brien\" + 0.001*\"hear sweet voice\" + 0.001*\"bear touch dead\" + 0.001*\"mrs brien say\" + 0.001*\"old woman house\" + 0.001*\"say old man\" + 0.001*\"seven year old\"'),\n",
       "  (2,\n",
       "   '0.003*\"se ou jackalse\" + 0.001*\"se ou wolf\" + 0.001*\"ou jackalse yust\" + 0.001*\"ju ju man\" + 0.001*\"tell year ago\" + 0.001*\"village cream puff\" + 0.001*\"exclaim foolish creature\" + 0.001*\"cahnt har ly\" + 0.001*\"say old woman\" + 0.000*\"policeman village cream\"'),\n",
       "  (3,\n",
       "   '0.001*\"say old man\" + 0.001*\"old man say\" + 0.001*\"old man tell\" + 0.001*\"rip van winkle\" + 0.001*\"old man leave\" + 0.001*\"say old woman\" + 0.001*\"little old woman\" + 0.001*\"say young man\" + 0.000*\"great crowd people\" + 0.000*\"new bear babe\"'),\n",
       "  (4,\n",
       "   '0.001*\"say king son\" + 0.001*\"say old woman\" + 0.001*\"old man daughter\" + 0.001*\"say old man\" + 0.001*\"gold buckskin whincher\" + 0.001*\"old people remember\" + 0.001*\"fly branch tree\" + 0.001*\"serve master year\" + 0.001*\"old woman daughter\" + 0.001*\"earth open eye\"'),\n",
       "  (5,\n",
       "   '0.001*\"mount horse ride\" + 0.001*\"king say good\" + 0.001*\"say oh yes\" + 0.001*\"learn magic art\" + 0.001*\"say old man\" + 0.001*\"st peter say\" + 0.001*\"long time ago\" + 0.001*\"young man son\" + 0.001*\"come gather honey\" + 0.001*\"old woman say\"'),\n",
       "  (6,\n",
       "   '0.001*\"little old woman\" + 0.001*\"potato face blind\" + 0.001*\"face blind man\" + 0.001*\"say old man\" + 0.001*\"oo oo oo\" + 0.001*\"door fling open\" + 0.001*\"old man say\" + 0.001*\"say potato face\" + 0.001*\"long time ago\" + 0.001*\"come knock door\"'),\n",
       "  (7,\n",
       "   '0.001*\"say old man\" + 0.001*\"say old woman\" + 0.001*\"old woman say\" + 0.001*\"happy hunting ground\" + 0.001*\"old man old\" + 0.001*\"old woman come\" + 0.001*\"old man say\" + 0.001*\"old brown sister\" + 0.001*\"long long time\" + 0.001*\"long time ago\"')])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf2_2, ldaMulticore_tf2_2_topics = LDAMulticore_model(vectorizer = tf2, doc_term = tf2_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf2_2, ldaMulticore_tf2_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6beecf8050>,\n",
       " [(0,\n",
       "   '0.000*\"white corn\" + 0.000*\"food cow\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"old man\" + 0.000*\"old dragon\" + 0.000*\"time cat\" + 0.000*\"manhattan island\" + 0.000*\"cow cow\" + 0.000*\"cat tail\"'),\n",
       "  (1,\n",
       "   '0.001*\"old man\" + 0.001*\"old woman\" + 0.001*\"young man\" + 0.000*\"say king\" + 0.000*\"little hahsie\" + 0.000*\"long time\" + 0.000*\"say old\" + 0.000*\"king say\" + 0.000*\"say prince\" + 0.000*\"till come\"'),\n",
       "  (2,\n",
       "   '0.000*\"white corn\" + 0.000*\"say musician\" + 0.000*\"grandmother spider\" + 0.000*\"beautiful field\" + 0.000*\"christmas tree\" + 0.000*\"little goat\" + 0.000*\"old man\" + 0.000*\"dive bring\" + 0.000*\"kill eat\" + 0.000*\"house boy\"'),\n",
       "  (3,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"bush rat\" + 0.000*\"sea serpent\" + 0.000*\"little bird\" + 0.000*\"holy virgin\" + 0.000*\"say virgin\" + 0.000*\"come pursuit\" + 0.000*\"ruler heaven\" + 0.000*\"king sheep\" + 0.000*\"animal bird\"'),\n",
       "  (4,\n",
       "   '0.001*\"old man\" + 0.000*\"water demon\" + 0.000*\"black fellow\" + 0.000*\"mountain lion\" + 0.000*\"thou lt\" + 0.000*\"golden ducat\" + 0.000*\"mrs brien\" + 0.000*\"think peasant\" + 0.000*\"little boy\" + 0.000*\"say peasant\"'),\n",
       "  (5,\n",
       "   '0.000*\"oo oo\" + 0.000*\"head servant\" + 0.000*\"lady moon\" + 0.000*\"brown sister\" + 0.000*\"oom jakhal\" + 0.000*\"oo oo oo\" + 0.000*\"great spirit\" + 0.000*\"man moon\" + 0.000*\"yum yum\" + 0.000*\"ha ha\"'),\n",
       "  (6,\n",
       "   '0.002*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.001*\"se ou\" + 0.000*\"se ou jackalse\" + 0.000*\"yellow lily\" + 0.000*\"king lion\" + 0.000*\"main street\" + 0.000*\"old woman\" + 0.000*\"rich brother\" + 0.000*\"dat se\"'),\n",
       "  (7,\n",
       "   '0.000*\"white feather\" + 0.000*\"big brother\" + 0.000*\"little house\" + 0.000*\"old farmer\" + 0.000*\"young man\" + 0.000*\"old man\" + 0.000*\"little brother\" + 0.000*\"dead body\" + 0.000*\"church yard\" + 0.000*\"house little house\"')])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf3_2, ldaMulticore_tf3_2_topics = LDAMulticore_model(vectorizer = tf3, doc_term = tf3_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf3_2, ldaMulticore_tf3_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb3f3d390>,\n",
       " [(0,\n",
       "   '0.000*\"say musician\" + 0.000*\"lady moon\" + 0.000*\"little hare\" + 0.000*\"little brother\" + 0.000*\"great spirit\" + 0.000*\"say moon\" + 0.000*\"die die\" + 0.000*\"christ child\" + 0.000*\"die live\" + 0.000*\"old man\"'),\n",
       "  (1,\n",
       "   '0.000*\"food cow\" + 0.000*\"little bird\" + 0.000*\"old dragon\" + 0.000*\"point eye\" + 0.000*\"fly cow\" + 0.000*\"st peter\" + 0.000*\"stroke cut\" + 0.000*\"look balloon\" + 0.000*\"wintry day\" + 0.000*\"stoop stroke\"'),\n",
       "  (2,\n",
       "   '0.002*\"old man\" + 0.001*\"old woman\" + 0.001*\"young man\" + 0.001*\"say king\" + 0.000*\"long time\" + 0.000*\"run away\" + 0.000*\"say old\" + 0.000*\"king daughter\" + 0.000*\"little girl\" + 0.000*\"come home\"'),\n",
       "  (3,\n",
       "   '0.000*\"oo oo\" + 0.000*\"big brother\" + 0.000*\"rich brother\" + 0.000*\"oom jakhal\" + 0.000*\"manhattan island\" + 0.000*\"little brother\" + 0.000*\"poor brother\" + 0.000*\"head chief\" + 0.000*\"dead body\" + 0.000*\"wirreenun say\"'),\n",
       "  (4,\n",
       "   '0.001*\"black fellow\" + 0.001*\"sea serpent\" + 0.001*\"main street\" + 0.000*\"salt water\" + 0.000*\"little boy\" + 0.000*\"make axe\" + 0.000*\"cool sweet\" + 0.000*\"wood chopper\" + 0.000*\"certain wood\" + 0.000*\"eye bit\"'),\n",
       "  (5,\n",
       "   '0.000*\"old man\" + 0.000*\"brown sister\" + 0.000*\"old farmer\" + 0.000*\"golden ducat\" + 0.000*\"thou lt\" + 0.000*\"christmas tree\" + 0.000*\"man moon\" + 0.000*\"yum yum\" + 0.000*\"cat tail\" + 0.000*\"rat mouse\"'),\n",
       "  (6,\n",
       "   '0.001*\"hoo hoo\" + 0.001*\"water demon\" + 0.000*\"white corn\" + 0.000*\"head servant\" + 0.000*\"grandmother spider\" + 0.000*\"se ole\" + 0.000*\"mrs brien\" + 0.000*\"king bird\" + 0.000*\"time cat\" + 0.000*\"king sheep\"'),\n",
       "  (7,\n",
       "   '0.000*\"golden haired\" + 0.000*\"little lamb\" + 0.000*\"yellow dog\" + 0.000*\"wise woman\" + 0.000*\"old man\" + 0.000*\"think peasant\" + 0.000*\"blow away\" + 0.000*\"church yard\" + 0.000*\"spin spin\" + 0.000*\"man forget\"'),\n",
       "  (8,\n",
       "   '0.001*\"bush rat\" + 0.000*\"little house\" + 0.000*\"birch tree\" + 0.000*\"mountain lion\" + 0.000*\"bend break\" + 0.000*\"old man\" + 0.000*\"ruler heaven\" + 0.000*\"overtake throw\" + 0.000*\"pocket handkerchief\" + 0.000*\"croak frog\"'),\n",
       "  (9,\n",
       "   '0.003*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"se ou\" + 0.001*\"little hahsie\" + 0.001*\"king lion\" + 0.000*\"se hahsie\" + 0.000*\"old hendrik\" + 0.000*\"ou sculpat\" + 0.000*\"dat se\" + 0.000*\"young man\"')])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_3, ldaMulticore_tf1_3_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_3, ldaMulticore_tf1_3_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c4646b0d0>,\n",
       " [(0,\n",
       "   '0.001*\"say old man\" + 0.001*\"door fling open\" + 0.001*\"say old woman\" + 0.001*\"seven year day\" + 0.001*\"cow cow milk\" + 0.001*\"poor old man\" + 0.001*\"run away master\" + 0.001*\"live far away\" + 0.001*\"wait long time\" + 0.001*\"oh yes say\"'),\n",
       "  (1,\n",
       "   '0.001*\"little old woman\" + 0.001*\"old woman say\" + 0.001*\"mount horse ride\" + 0.001*\"say old man\" + 0.001*\"water ju ju\" + 0.001*\"exclaim foolish creature\" + 0.001*\"come gather honey\" + 0.001*\"draw nigh unto\" + 0.001*\"poor man say\" + 0.001*\"say poor man\"'),\n",
       "  (2,\n",
       "   '0.001*\"happy hunting ground\" + 0.001*\"say old woman\" + 0.001*\"rip van winkle\" + 0.001*\"old man say\" + 0.001*\"say old man\" + 0.001*\"say old peter\" + 0.001*\"tell wonderful story\" + 0.001*\"hear voice look\" + 0.001*\"say mrs brien\" + 0.001*\"long long ago\"'),\n",
       "  (3,\n",
       "   '0.002*\"face blind man\" + 0.002*\"potato face blind\" + 0.001*\"old man daughter\" + 0.001*\"say old man\" + 0.001*\"say potato face\" + 0.001*\"old woman say\" + 0.001*\"fling open door\" + 0.001*\"little old man\" + 0.001*\"old man say\" + 0.001*\"old woman daughter\"'),\n",
       "  (4,\n",
       "   '0.001*\"good turn deserve\" + 0.001*\"fast friend say\" + 0.001*\"old man say\" + 0.001*\"tumble head heel\" + 0.001*\"little old woman\" + 0.001*\"long long ago\" + 0.001*\"run away hide\" + 0.001*\"horse bridle saddle\" + 0.001*\"day sun set\" + 0.000*\"know know say\"'),\n",
       "  (5,\n",
       "   '0.001*\"die broken heart\" + 0.001*\"say king son\" + 0.001*\"gold buckskin whincher\" + 0.001*\"illustration ford publish\" + 0.001*\"old man come\" + 0.001*\"little old woman\" + 0.001*\"fairy book andrew\" + 0.001*\"book andrew lang\" + 0.001*\"say old man\" + 0.001*\"lang longmans green\"'),\n",
       "  (6,\n",
       "   '0.001*\"say old man\" + 0.001*\"village cream puff\" + 0.001*\"ha ha ha\" + 0.001*\"grow bank river\" + 0.001*\"fly branch tree\" + 0.001*\"st nicholas come\" + 0.001*\"old people remember\" + 0.001*\"peter potato blossom\" + 0.001*\"make young man\" + 0.001*\"king son come\"'),\n",
       "  (7,\n",
       "   '0.001*\"head rest hand\" + 0.001*\"quack quack quack\" + 0.001*\"away long time\" + 0.001*\"say old man\" + 0.001*\"say young man\" + 0.001*\"say little bird\" + 0.000*\"bow head ground\" + 0.000*\"way mother say\" + 0.000*\"man woman child\" + 0.000*\"brother sister play\"'),\n",
       "  (8,\n",
       "   '0.001*\"st peter say\" + 0.001*\"say old woman\" + 0.001*\"spend long hour\" + 0.001*\"hot summer day\" + 0.001*\"little old woman\" + 0.001*\"green grass grow\" + 0.001*\"say old man\" + 0.001*\"little old man\" + 0.001*\"say st peter\" + 0.001*\"old woman come\"'),\n",
       "  (9,\n",
       "   '0.002*\"se ou jackalse\" + 0.001*\"se ou wolf\" + 0.001*\"long time ago\" + 0.001*\"make sign cross\" + 0.001*\"ju ju man\" + 0.001*\"say old woman\" + 0.001*\"poor old woman\" + 0.001*\"touch dead body\" + 0.001*\"ou jackalse yust\" + 0.001*\"bear touch dead\"')])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf2_3, ldaMulticore_tf2_3_topics = LDAMulticore_model(vectorizer = tf2, doc_term = tf2_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf2_3, ldaMulticore_tf2_3_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c186479d0>,\n",
       " [(0,\n",
       "   '0.000*\"little lamb\" + 0.000*\"food cow\" + 0.000*\"cow cow\" + 0.000*\"shall walk\" + 0.000*\"cat tail\" + 0.000*\"point eye\" + 0.000*\"fly cow\" + 0.000*\"love slay\" + 0.000*\"way quiet\" + 0.000*\"holy virgin\"'),\n",
       "  (1,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"overtake throw\" + 0.000*\"pocket handkerchief\" + 0.000*\"christmas tree\" + 0.000*\"time cat\" + 0.000*\"great spirit\" + 0.000*\"dead body\" + 0.000*\"serpent king\" + 0.000*\"seize axe\" + 0.000*\"stroke cut\"'),\n",
       "  (2,\n",
       "   '0.001*\"old man\" + 0.001*\"yellow lily\" + 0.001*\"war eagle\" + 0.000*\"head servant\" + 0.000*\"mice people\" + 0.000*\"brown sister\" + 0.000*\"king sheep\" + 0.000*\"young man\" + 0.000*\"little boy\" + 0.000*\"captain guard\"'),\n",
       "  (3,\n",
       "   '0.000*\"golden ducat\" + 0.000*\"wood chopper\" + 0.000*\"make axe\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"oak forest\" + 0.000*\"pride joy\" + 0.000*\"fine tree\" + 0.000*\"blow away\"'),\n",
       "  (4,\n",
       "   '0.000*\"black fellow\" + 0.000*\"white corn\" + 0.000*\"main street\" + 0.000*\"little house\" + 0.000*\"grandmother spider\" + 0.000*\"old dragon\" + 0.000*\"head chief\" + 0.000*\"milk white\" + 0.000*\"house little house\" + 0.000*\"little house little\"'),\n",
       "  (5,\n",
       "   '0.000*\"sea serpent\" + 0.000*\"yellow dog\" + 0.000*\"old farmer\" + 0.000*\"drinking horn\" + 0.000*\"beautiful field\" + 0.000*\"mother sheep\" + 0.000*\"st anthony\" + 0.000*\"steal food\" + 0.000*\"little boy\" + 0.000*\"spot dog\"'),\n",
       "  (6,\n",
       "   '0.000*\"oo oo\" + 0.000*\"oom jakhal\" + 0.000*\"oo oo oo\" + 0.000*\"manhattan island\" + 0.000*\"st peter\" + 0.000*\"day hunter\" + 0.000*\"church yard\" + 0.000*\"mango fruit\" + 0.000*\"eat fruit\" + 0.000*\"poor brâhmaṇ\"'),\n",
       "  (7,\n",
       "   '0.000*\"little brother\" + 0.000*\"ou sculpat\" + 0.000*\"big brother\" + 0.000*\"lady moon\" + 0.000*\"old woman\" + 0.000*\"little hahsie\" + 0.000*\"little bird\" + 0.000*\"thou lt\" + 0.000*\"christ child\" + 0.000*\"animal bird\"'),\n",
       "  (8,\n",
       "   '0.001*\"old man\" + 0.001*\"old woman\" + 0.001*\"young man\" + 0.000*\"long time\" + 0.000*\"say king\" + 0.000*\"king daughter\" + 0.000*\"little girl\" + 0.000*\"say old\" + 0.000*\"run away\" + 0.000*\"look like\"'),\n",
       "  (9,\n",
       "   '0.002*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.001*\"se ou\" + 0.001*\"se ou jackalse\" + 0.000*\"bush rat\" + 0.000*\"old hendrik\" + 0.000*\"king lion\" + 0.000*\"white corn\" + 0.000*\"se ole\" + 0.000*\"blue corn\"')])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf3_3, ldaMulticore_tf3_3_topics = LDAMulticore_model(vectorizer = tf3, doc_term = tf3_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf3_3, ldaMulticore_tf3_3_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bdecb6fd0>,\n",
       " [(0,\n",
       "   '0.004*\"young man\" + 0.002*\"old woman\" + 0.002*\"old man\" + 0.001*\"long time\" + 0.001*\"king daughter\" + 0.001*\"return home\" + 0.001*\"come home\" + 0.001*\"far away\" + 0.001*\"father mother\" + 0.001*\"tell story\"'),\n",
       "  (1,\n",
       "   '0.003*\"old woman\" + 0.002*\"old man\" + 0.001*\"say king\" + 0.001*\"poor man\" + 0.001*\"young man\" + 0.001*\"come home\" + 0.001*\"run away\" + 0.001*\"man say\" + 0.001*\"long time\" + 0.001*\"open door\"'),\n",
       "  (2,\n",
       "   '0.003*\"old man\" + 0.002*\"old woman\" + 0.001*\"young man\" + 0.001*\"little girl\" + 0.001*\"little boy\" + 0.001*\"look like\" + 0.001*\"long time\" + 0.001*\"say old\" + 0.001*\"far away\" + 0.001*\"fly away\"'),\n",
       "  (3,\n",
       "   '0.003*\"ou jackalse\" + 0.003*\"old woman\" + 0.002*\"king son\" + 0.002*\"ou wolf\" + 0.002*\"young man\" + 0.001*\"say king\" + 0.001*\"old man\" + 0.001*\"se ou\" + 0.001*\"king daughter\" + 0.001*\"thou hast\"'),\n",
       "  (4,\n",
       "   '0.008*\"old man\" + 0.003*\"old woman\" + 0.002*\"say old\" + 0.001*\"little girl\" + 0.001*\"long time\" + 0.001*\"young man\" + 0.001*\"man say\" + 0.001*\"say little\" + 0.001*\"run away\" + 0.001*\"man come\"')])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_cv1_1, ldaMulticore_cv1_1_topics = LDAMulticore_model(vectorizer = cv1, doc_term = cv1_matrix, \n",
    "                                                               num_topics = 5, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_cv1_1, ldaMulticore_cv1_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bdf07d810>,\n",
       " [(0,\n",
       "   '0.010*\"old man\" + 0.006*\"old woman\" + 0.003*\"young man\" + 0.002*\"say old\" + 0.001*\"man say\" + 0.001*\"long time\" + 0.001*\"come home\" + 0.001*\"little girl\" + 0.001*\"man come\" + 0.001*\"little boy\"'),\n",
       "  (1,\n",
       "   '0.001*\"young man\" + 0.001*\"dweller asgard\" + 0.001*\"old woman\" + 0.001*\"tsarevich ivan\" + 0.001*\"say king\" + 0.001*\"far away\" + 0.001*\"old man\" + 0.001*\"long time\" + 0.001*\"ju ju\" + 0.001*\"look like\"'),\n",
       "  (2,\n",
       "   '0.010*\"ou jackalse\" + 0.007*\"ou wolf\" + 0.004*\"se ou\" + 0.002*\"little hahsie\" + 0.001*\"say lad\" + 0.001*\"ou sculpat\" + 0.001*\"mr fox\" + 0.001*\"king lion\" + 0.001*\"old hendrik\" + 0.001*\"dat se\"'),\n",
       "  (3,\n",
       "   '0.002*\"poor man\" + 0.002*\"old woman\" + 0.001*\"mrs brien\" + 0.001*\"good people\" + 0.001*\"say king\" + 0.001*\"rich man\" + 0.001*\"rich brother\" + 0.001*\"st peter\" + 0.001*\"say man\" + 0.001*\"young man\"'),\n",
       "  (4,\n",
       "   '0.002*\"old woman\" + 0.001*\"king son\" + 0.001*\"king daughter\" + 0.001*\"old man\" + 0.001*\"say king\" + 0.001*\"say little\" + 0.001*\"king say\" + 0.001*\"long time\" + 0.001*\"king queen\" + 0.001*\"little girl\"'),\n",
       "  (5,\n",
       "   '0.002*\"young man\" + 0.002*\"say king\" + 0.002*\"old man\" + 0.001*\"king son\" + 0.001*\"say prince\" + 0.001*\"king daughter\" + 0.001*\"till come\" + 0.001*\"prince say\" + 0.001*\"old woman\" + 0.001*\"long time\"'),\n",
       "  (6,\n",
       "   '0.004*\"old woman\" + 0.002*\"thou hast\" + 0.002*\"thou art\" + 0.001*\"king son\" + 0.001*\"thou wilt\" + 0.001*\"hast thou\" + 0.001*\"thou shalt\" + 0.001*\"dost thou\" + 0.001*\"long time\" + 0.001*\"young man\"'),\n",
       "  (7,\n",
       "   '0.002*\"young man\" + 0.002*\"old woman\" + 0.001*\"king daughter\" + 0.001*\"golden apple\" + 0.001*\"little fox\" + 0.001*\"apple tree\" + 0.001*\"father mother\" + 0.001*\"young prince\" + 0.001*\"come home\" + 0.001*\"say king\"')])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_cv1_2, ldaMulticore_cv1_2_topics = LDAMulticore_model(vectorizer = cv1, doc_term = cv1_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_cv1_2, ldaMulticore_cv1_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb2104250>,\n",
       " [(0,\n",
       "   '0.000*\"dry grass\" + 0.000*\"say stag\" + 0.000*\"holy place\" + 0.000*\"jack knife\" + 0.000*\"away tree\" + 0.000*\"ring centre\" + 0.000*\"black river\" + 0.000*\"green mountain\" + 0.000*\"pot hole\" + 0.000*\"look cave\"'),\n",
       "  (1,\n",
       "   '0.001*\"oo oo\" + 0.001*\"oom jakhal\" + 0.000*\"little bird\" + 0.000*\"oom leeuw\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"animal bird\" + 0.000*\"dead body\" + 0.000*\"eagle hawk\" + 0.000*\"just reach\"'),\n",
       "  (2,\n",
       "   '0.001*\"food cow\" + 0.001*\"ruler heaven\" + 0.000*\"point eye\" + 0.000*\"fly cow\" + 0.000*\"water melon\" + 0.000*\"yang oerlang\" + 0.000*\"game hunter\" + 0.000*\"mud bank\" + 0.000*\"use big\" + 0.000*\"share food\"'),\n",
       "  (3,\n",
       "   '0.001*\"water demon\" + 0.001*\"sea serpent\" + 0.001*\"rich brother\" + 0.001*\"head servant\" + 0.001*\"poor brother\" + 0.001*\"golden ducat\" + 0.000*\"manhattan island\" + 0.000*\"great spirit\" + 0.000*\"water salt\" + 0.000*\"old woman\"'),\n",
       "  (4,\n",
       "   '0.001*\"yellow lily\" + 0.000*\"st anthony\" + 0.000*\"spin spin\" + 0.000*\"say deer\" + 0.000*\"spin spinning\" + 0.000*\"good saint\" + 0.000*\"run race\" + 0.000*\"beat run\" + 0.000*\"ready away\" + 0.000*\"gall liver\"'),\n",
       "  (5,\n",
       "   '0.001*\"little lamb\" + 0.001*\"mice people\" + 0.001*\"war eagle\" + 0.000*\"hold bone\" + 0.000*\"pull sea\" + 0.000*\"ho old\" + 0.000*\"say lamb\" + 0.000*\"eagle lodge\" + 0.000*\"animal people\" + 0.000*\"say toad\"'),\n",
       "  (6,\n",
       "   '0.001*\"grandmother spider\" + 0.001*\"white corn\" + 0.000*\"man moon\" + 0.000*\"blow away\" + 0.000*\"steal food\" + 0.000*\"tall tall\" + 0.000*\"dive bring\" + 0.000*\"sole foot\" + 0.000*\"farmer cross\" + 0.000*\"bring sand\"'),\n",
       "  (7,\n",
       "   '0.001*\"old woman\" + 0.001*\"king daughter\" + 0.001*\"king say\" + 0.001*\"little house\" + 0.001*\"say prince\" + 0.001*\"say king\" + 0.001*\"king son\" + 0.001*\"white feather\" + 0.001*\"thou art\" + 0.001*\"white corn\"'),\n",
       "  (8,\n",
       "   '0.001*\"little hahsie\" + 0.001*\"ou sculpat\" + 0.001*\"se hahsie\" + 0.001*\"se ole\" + 0.001*\"brown sister\" + 0.000*\"overtake throw\" + 0.000*\"pocket handkerchief\" + 0.000*\"dat honey\" + 0.000*\"yum yum\" + 0.000*\"dis way\"'),\n",
       "  (9,\n",
       "   '0.001*\"main street\" + 0.001*\"christ child\" + 0.001*\"yellow dog\" + 0.000*\"milk white\" + 0.000*\"live forever\" + 0.000*\"day feast\" + 0.000*\"good dame\" + 0.000*\"spot dog\" + 0.000*\"tail dog\" + 0.000*\"dinner party\"'),\n",
       "  (10,\n",
       "   '0.001*\"birch tree\" + 0.001*\"war eagle\" + 0.001*\"mountain lion\" + 0.001*\"bend break\" + 0.000*\"brown sister\" + 0.000*\"blow hard\" + 0.000*\"say grasshopper\" + 0.000*\"holy virgin\" + 0.000*\"love slay\" + 0.000*\"way quiet\"'),\n",
       "  (11,\n",
       "   '0.001*\"bush rat\" + 0.001*\"big brother\" + 0.001*\"old farmer\" + 0.000*\"cat tail\" + 0.000*\"milk cat\" + 0.000*\"stroke cut\" + 0.000*\"wintry day\" + 0.000*\"stoop stroke\" + 0.000*\"mango fruit\" + 0.000*\"say gratitude\"'),\n",
       "  (12,\n",
       "   '0.004*\"old man\" + 0.002*\"young man\" + 0.002*\"old woman\" + 0.001*\"little boy\" + 0.001*\"poor man\" + 0.001*\"say old\" + 0.001*\"long time\" + 0.001*\"run away\" + 0.001*\"little girl\" + 0.001*\"man say\"'),\n",
       "  (13,\n",
       "   '0.000*\"time cat\" + 0.000*\"beautiful field\" + 0.000*\"serpent king\" + 0.000*\"head chief\" + 0.000*\"let monkey\" + 0.000*\"wirreenun say\" + 0.000*\"sun ask\" + 0.000*\"live earth\" + 0.000*\"cat eat\" + 0.000*\"cat catch\"'),\n",
       "  (14,\n",
       "   '0.005*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.002*\"se ou\" + 0.001*\"king lion\" + 0.001*\"dat se\" + 0.001*\"thou lt\" + 0.001*\"old dragon\" + 0.000*\"old hendrik\" + 0.000*\"se dey\" + 0.000*\"like dat\"')])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_4, ldaMulticore_tf1_4_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 15, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_4, ldaMulticore_tf1_4_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb1ebcb50>,\n",
       " [(0,\n",
       "   '0.001*\"yellow lily\" + 0.001*\"white corn\" + 0.001*\"little house\" + 0.000*\"grandmother spider\" + 0.000*\"yellow dog\" + 0.000*\"croak frog\" + 0.000*\"dead body\" + 0.000*\"little goat\" + 0.000*\"hide hill\" + 0.000*\"time dog\"'),\n",
       "  (1,\n",
       "   '0.000*\"lady moon\" + 0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"great spirit\" + 0.000*\"thou lt\" + 0.000*\"dat honey\" + 0.000*\"blow away\" + 0.000*\"long island\" + 0.000*\"ole missis\"'),\n",
       "  (2,\n",
       "   '0.000*\"bend break\" + 0.000*\"birch tree\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"wirreenun say\" + 0.000*\"live earth\" + 0.000*\"blow hard\" + 0.000*\"sun moon\" + 0.000*\"water come\" + 0.000*\"sun ask\"'),\n",
       "  (3,\n",
       "   '0.003*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"se ou\" + 0.001*\"little hahsie\" + 0.001*\"king lion\" + 0.001*\"old hendrik\" + 0.001*\"ou sculpat\" + 0.001*\"se hahsie\" + 0.000*\"big brother\" + 0.000*\"se ole\"'),\n",
       "  (4,\n",
       "   '0.001*\"main street\" + 0.000*\"little lamb\" + 0.000*\"mice people\" + 0.000*\"say farmer\" + 0.000*\"yes baasje\" + 0.000*\"hoo hoo\" + 0.000*\"milk white\" + 0.000*\"look balloon\" + 0.000*\"hold bone\" + 0.000*\"pull sea\"'),\n",
       "  (5,\n",
       "   '0.000*\"old dragon\" + 0.000*\"pocket handkerchief\" + 0.000*\"church yard\" + 0.000*\"animal bird\" + 0.000*\"water salt\" + 0.000*\"christ child\" + 0.000*\"head chief\" + 0.000*\"yangtze kiang\" + 0.000*\"overtake throw\" + 0.000*\"nether world\"'),\n",
       "  (6,\n",
       "   '0.001*\"bush rat\" + 0.000*\"golden ducat\" + 0.000*\"manhattan island\" + 0.000*\"man moon\" + 0.000*\"steal food\" + 0.000*\"stroke cut\" + 0.000*\"wintry day\" + 0.000*\"stoop stroke\" + 0.000*\"say gratitude\" + 0.000*\"cut serpent\"'),\n",
       "  (7,\n",
       "   '0.000*\"mountain lion\" + 0.000*\"time cat\" + 0.000*\"spin spin\" + 0.000*\"good dame\" + 0.000*\"magic ring\" + 0.000*\"emperor send\" + 0.000*\"say sparrow\" + 0.000*\"spin spinning\" + 0.000*\"sparrow begin\" + 0.000*\"dog cat\"'),\n",
       "  (8,\n",
       "   '0.000*\"holy virgin\" + 0.000*\"say virgin\" + 0.000*\"come pursuit\" + 0.000*\"little bird\" + 0.000*\"let monkey\" + 0.000*\"way quiet\" + 0.000*\"love slay\" + 0.000*\"enemy love\" + 0.000*\"curse say\" + 0.000*\"mango fruit\"'),\n",
       "  (9,\n",
       "   '0.003*\"old man\" + 0.002*\"old woman\" + 0.002*\"young man\" + 0.001*\"long time\" + 0.001*\"say king\" + 0.001*\"say old\" + 0.001*\"poor man\" + 0.001*\"little boy\" + 0.001*\"run away\" + 0.001*\"little girl\"'),\n",
       "  (10,\n",
       "   '0.001*\"hoo hoo\" + 0.001*\"water demon\" + 0.000*\"oom jakhal\" + 0.000*\"wood chopper\" + 0.000*\"make axe\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"oak forest\" + 0.000*\"pride joy\"'),\n",
       "  (11,\n",
       "   '0.000*\"black fellow\" + 0.000*\"rich brother\" + 0.000*\"say musician\" + 0.000*\"head servant\" + 0.000*\"poor brother\" + 0.000*\"think peasant\" + 0.000*\"little hare\" + 0.000*\"christ child\" + 0.000*\"come woman\" + 0.000*\"soon learn\"')])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_5, ldaMulticore_tf1_5_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 12, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_5, ldaMulticore_tf1_5_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c447ba090>,\n",
       " [(0,\n",
       "   '0.000*\"water demon\" + 0.000*\"sea serpent\" + 0.000*\"white corn\" + 0.000*\"grandmother spider\" + 0.000*\"thou lt\" + 0.000*\"brown sister\" + 0.000*\"wirreenun say\" + 0.000*\"st anthony\" + 0.000*\"hold bone\" + 0.000*\"day feast\"'),\n",
       "  (1,\n",
       "   '0.000*\"say musician\" + 0.000*\"white corn\" + 0.000*\"christmas tree\" + 0.000*\"blue corn\" + 0.000*\"christ child\" + 0.000*\"corn blue\" + 0.000*\"king sheep\" + 0.000*\"serpent king\" + 0.000*\"little goat\" + 0.000*\"fine tree\"'),\n",
       "  (2,\n",
       "   '0.000*\"hoo hoo\" + 0.000*\"yellow lily\" + 0.000*\"bush rat\" + 0.000*\"bend break\" + 0.000*\"ou sculpat\" + 0.000*\"croak frog\" + 0.000*\"brown sister\" + 0.000*\"hide hill\" + 0.000*\"ruler heaven\" + 0.000*\"blow hard\"'),\n",
       "  (3,\n",
       "   '0.000*\"big brother\" + 0.000*\"oo oo\" + 0.000*\"golden haired\" + 0.000*\"food cow\" + 0.000*\"oom jakhal\" + 0.000*\"king gold\" + 0.000*\"church yard\" + 0.000*\"se ole\" + 0.000*\"water death\" + 0.000*\"overtake throw\"'),\n",
       "  (4,\n",
       "   '0.000*\"little lamb\" + 0.000*\"old farmer\" + 0.000*\"yellow dog\" + 0.000*\"old dragon\" + 0.000*\"head chief\" + 0.000*\"let monkey\" + 0.000*\"time dog\" + 0.000*\"look balloon\" + 0.000*\"pull sea\" + 0.000*\"say serpent\"'),\n",
       "  (5,\n",
       "   '0.000*\"lady moon\" + 0.000*\"golden ducat\" + 0.000*\"rat mouse\" + 0.000*\"die live\" + 0.000*\"live forever\" + 0.000*\"magic wand\" + 0.000*\"great value\" + 0.000*\"magic ring\" + 0.000*\"christ child\" + 0.000*\"young hero\"'),\n",
       "  (6,\n",
       "   '0.000*\"black fellow\" + 0.000*\"main street\" + 0.000*\"mountain lion\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"beautiful field\" + 0.000*\"home work\" + 0.000*\"eagle hawk\" + 0.000*\"wintry day\" + 0.000*\"stroke cut\"'),\n",
       "  (7,\n",
       "   '0.002*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.001*\"se ou\" + 0.000*\"little hahsie\" + 0.000*\"king lion\" + 0.000*\"rich brother\" + 0.000*\"head servant\" + 0.000*\"se hahsie\" + 0.000*\"poor brother\" + 0.000*\"mrs brien\"')])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf4_1, ldaMulticore_tf4_1_topics = LDAMulticore_model(vectorizer = tf4, doc_term = tf4_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf4_1, ldaMulticore_tf4_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb210c910>,\n",
       " [(0,\n",
       "   '0.001*\"main street\" + 0.001*\"white corn\" + 0.000*\"rich brother\" + 0.000*\"old farmer\" + 0.000*\"grandmother spider\" + 0.000*\"old dragon\" + 0.000*\"poor brother\" + 0.000*\"man moon\" + 0.000*\"think peasant\" + 0.000*\"st anthony\"'),\n",
       "  (1,\n",
       "   '0.000*\"white corn\" + 0.000*\"mrs brien\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"christmas tree\" + 0.000*\"christ child\" + 0.000*\"spin spin\" + 0.000*\"tir na\" + 0.000*\"magic ring\" + 0.000*\"climb sky\"'),\n",
       "  (2,\n",
       "   '0.001*\"oo oo\" + 0.001*\"bend break\" + 0.001*\"big brother\" + 0.001*\"ou sculpat\" + 0.000*\"little hahsie\" + 0.000*\"croak frog\" + 0.000*\"brown sister\" + 0.000*\"oom jakhal\" + 0.000*\"hide hill\" + 0.000*\"blow hard\"'),\n",
       "  (3,\n",
       "   '0.000*\"food cow\" + 0.000*\"drinking horn\" + 0.000*\"time cat\" + 0.000*\"old chief\" + 0.000*\"mother sheep\" + 0.000*\"say moon\" + 0.000*\"steal food\" + 0.000*\"wirreenun say\" + 0.000*\"point eye\" + 0.000*\"fly cow\"'),\n",
       "  (4,\n",
       "   '0.001*\"bush rat\" + 0.001*\"head servant\" + 0.001*\"lady moon\" + 0.000*\"golden ducat\" + 0.000*\"brown sister\" + 0.000*\"se ole\" + 0.000*\"let monkey\" + 0.000*\"dat honey\" + 0.000*\"let hand\" + 0.000*\"monkey think\"'),\n",
       "  (5,\n",
       "   '0.001*\"say musician\" + 0.000*\"little lamb\" + 0.000*\"yellow dog\" + 0.000*\"thou lt\" + 0.000*\"salt water\" + 0.000*\"water salt\" + 0.000*\"pull sea\" + 0.000*\"man wolf\" + 0.000*\"make shudder\" + 0.000*\"poor brâhmaṇ\"'),\n",
       "  (6,\n",
       "   '0.001*\"water demon\" + 0.001*\"yellow lily\" + 0.000*\"little hahsie\" + 0.000*\"manhattan island\" + 0.000*\"cat tail\" + 0.000*\"beautiful field\" + 0.000*\"church yard\" + 0.000*\"wintry day\" + 0.000*\"stroke cut\" + 0.000*\"stoop stroke\"'),\n",
       "  (7,\n",
       "   '0.001*\"sea serpent\" + 0.001*\"mountain lion\" + 0.000*\"ruler heaven\" + 0.000*\"serpent king\" + 0.000*\"make axe\" + 0.000*\"wood chopper\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"rat mouse\"'),\n",
       "  (8,\n",
       "   '0.003*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"se ou\" + 0.001*\"black fellow\" + 0.001*\"king lion\" + 0.000*\"old hendrik\" + 0.000*\"dat se\" + 0.000*\"king sheep\" + 0.000*\"little goat\" + 0.000*\"se dey\"'),\n",
       "  (9,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"golden haired\" + 0.000*\"left foot\" + 0.000*\"hold bone\" + 0.000*\"look balloon\" + 0.000*\"golden basin\" + 0.000*\"way quiet\" + 0.000*\"love slay\" + 0.000*\"enemy love\" + 0.000*\"curse say\"')])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################  The best LDA Model  ################\n",
    "\n",
    "ldaMulticore_tf4_2, ldaMulticore_tf4_2_topics = LDAMulticore_model(vectorizer = tf4, doc_term = tf4_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf4_2, ldaMulticore_tf4_2_topics\n",
    "\n",
    "# 0: poor vs. rich; 1: holiday; 2:family; 3: farm; 4: human&animals; 5: human&animals; 6: nature; 7: animal characters;\n",
    "# 8: animal characters; 9:love"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = [ldaMulticore_tf4_2, ldaMulticore_tf4_2_topics]\n",
    "\n",
    "with open('pickle_files/lda_bestmodel.pickle', 'wb') as to_write:\n",
    "    pickle.dump(lda_model, to_write)\n",
    "\n",
    "with open('pickle_files/lda_doc_term.pickle', 'wb') as to_write:\n",
    "    pickle.dump(tf4_matrix, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb1fc0090>,\n",
       " [(0,\n",
       "   '0.001*\"little hahsie\" + 0.001*\"king lion\" + 0.001*\"ou sculpat\" + 0.001*\"white corn\" + 0.001*\"oo oo\" + 0.001*\"se hahsie\" + 0.000*\"old farmer\" + 0.000*\"grandmother spider\" + 0.000*\"rich brother\" + 0.000*\"oom jakhal\"'),\n",
       "  (1,\n",
       "   '0.001*\"old dragon\" + 0.000*\"mango fruit\" + 0.000*\"poor brâhmaṇ\" + 0.000*\"mango tree\" + 0.000*\"yangtze kiang\" + 0.000*\"mice people\" + 0.000*\"milky way\" + 0.000*\"bring fruit\" + 0.000*\"nether world\" + 0.000*\"magic wand\"'),\n",
       "  (2,\n",
       "   '0.004*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"se ou\" + 0.001*\"water demon\" + 0.001*\"sea serpent\" + 0.000*\"dat se\" + 0.000*\"holy mother\" + 0.000*\"ho old\" + 0.000*\"dusty road\" + 0.000*\"ou baviyàan\"'),\n",
       "  (3,\n",
       "   '0.001*\"lady moon\" + 0.000*\"white corn\" + 0.000*\"mrs brien\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"old chief\" + 0.000*\"christmas tree\" + 0.000*\"christ child\" + 0.000*\"hold bone\" + 0.000*\"farmer greatly\"'),\n",
       "  (4,\n",
       "   '0.001*\"black fellow\" + 0.001*\"say musician\" + 0.001*\"old hendrik\" + 0.001*\"croak frog\" + 0.001*\"se ole\" + 0.000*\"hide hill\" + 0.000*\"brown sister\" + 0.000*\"man moon\" + 0.000*\"right se\" + 0.000*\"dat honey\"'),\n",
       "  (5,\n",
       "   '0.001*\"yellow lily\" + 0.001*\"head servant\" + 0.001*\"think peasant\" + 0.000*\"drinking horn\" + 0.000*\"magic ring\" + 0.000*\"serpent king\" + 0.000*\"cat tail\" + 0.000*\"mother sheep\" + 0.000*\"wirreenun say\" + 0.000*\"spin spin\"'),\n",
       "  (6,\n",
       "   '0.001*\"main street\" + 0.001*\"big brother\" + 0.000*\"brown sister\" + 0.000*\"thou lt\" + 0.000*\"ruler heaven\" + 0.000*\"hoo hoo\" + 0.000*\"close ground\" + 0.000*\"yum yum\" + 0.000*\"bite piece\" + 0.000*\"church yard\"'),\n",
       "  (7,\n",
       "   '0.000*\"king sheep\" + 0.000*\"captain guard\" + 0.000*\"tooth tooth\" + 0.000*\"rip open\" + 0.000*\"drink blood\" + 0.000*\"really dead\" + 0.000*\"let bury\" + 0.000*\"sheep say\" + 0.000*\"foolish man\" + 0.000*\"leeuw roar\"'),\n",
       "  (8,\n",
       "   '0.001*\"little lamb\" + 0.001*\"golden ducat\" + 0.000*\"little goat\" + 0.000*\"head chief\" + 0.000*\"steal food\" + 0.000*\"tall tall\" + 0.000*\"pull sea\" + 0.000*\"make shudder\" + 0.000*\"great value\" + 0.000*\"say lamb\"'),\n",
       "  (9,\n",
       "   '0.001*\"hoo hoo\" + 0.001*\"golden haired\" + 0.001*\"food cow\" + 0.000*\"let monkey\" + 0.000*\"wintry day\" + 0.000*\"point eye\" + 0.000*\"stroke cut\" + 0.000*\"stoop stroke\" + 0.000*\"fly cow\" + 0.000*\"say gratitude\"'),\n",
       "  (10,\n",
       "   '0.001*\"bush rat\" + 0.000*\"yellow dog\" + 0.000*\"time cat\" + 0.000*\"time dog\" + 0.000*\"dry grass\" + 0.000*\"say stag\" + 0.000*\"say deer\" + 0.000*\"remember message\" + 0.000*\"message deliver\" + 0.000*\"spot dog\"'),\n",
       "  (11,\n",
       "   '0.001*\"mountain lion\" + 0.001*\"bend break\" + 0.000*\"blow hard\" + 0.000*\"king gold\" + 0.000*\"live earth\" + 0.000*\"tree bend\" + 0.000*\"sun ask\" + 0.000*\"people rush\" + 0.000*\"ask water\" + 0.000*\"time moon\"')])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf4_3, ldaMulticore_tf4_3_topics = LDAMulticore_model(vectorizer = tf4, doc_term = tf4_matrix, \n",
    "                                                               num_topics = 12, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf4_3, ldaMulticore_tf4_3_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bac670c90>,\n",
       " [(0,\n",
       "   '0.001*\"ou wolf\" + 0.001*\"ou jackalse\" + 0.000*\"croak frog\" + 0.000*\"hide hill\" + 0.000*\"food cow\" + 0.000*\"old dragon\" + 0.000*\"ruler heaven\" + 0.000*\"brown sister\" + 0.000*\"wirreenun say\" + 0.000*\"wood chopper\"'),\n",
       "  (1,\n",
       "   '0.000*\"ou sculpat\" + 0.000*\"little hahsie\" + 0.000*\"brown sister\" + 0.000*\"beautiful field\" + 0.000*\"yum yum\" + 0.000*\"spin spin\" + 0.000*\"st anthony\" + 0.000*\"poor brâhmaṇ\" + 0.000*\"mango fruit\" + 0.000*\"se hahsie\"'),\n",
       "  (2,\n",
       "   '0.001*\"yellow lily\" + 0.001*\"water demon\" + 0.001*\"bush rat\" + 0.000*\"say musician\" + 0.000*\"lady moon\" + 0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"man moon\" + 0.000*\"look balloon\"'),\n",
       "  (3,\n",
       "   '0.000*\"oo oo\" + 0.000*\"king lion\" + 0.000*\"oom jakhal\" + 0.000*\"sun ask\" + 0.000*\"oom leeuw\" + 0.000*\"pull sea\" + 0.000*\"little hahsie\" + 0.000*\"let monkey\" + 0.000*\"hold bone\" + 0.000*\"drink blood\"'),\n",
       "  (4,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"think peasant\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"church yard\" + 0.000*\"say stag\" + 0.000*\"bring ring\" + 0.000*\"man wolf\" + 0.000*\"say arthur\" + 0.000*\"sit bundle\"'),\n",
       "  (5,\n",
       "   '0.001*\"sea serpent\" + 0.001*\"mountain lion\" + 0.000*\"big brother\" + 0.000*\"yellow dog\" + 0.000*\"time cat\" + 0.000*\"king sheep\" + 0.000*\"manhattan island\" + 0.000*\"serpent king\" + 0.000*\"captain guard\" + 0.000*\"game hunter\"'),\n",
       "  (6,\n",
       "   '0.001*\"white corn\" + 0.000*\"grandmother spider\" + 0.000*\"thou lt\" + 0.000*\"steal food\" + 0.000*\"overtake throw\" + 0.000*\"stroke cut\" + 0.000*\"wintry day\" + 0.000*\"stoop stroke\" + 0.000*\"break rock\" + 0.000*\"way quiet\"'),\n",
       "  (7,\n",
       "   '0.001*\"ou jackalse\" + 0.000*\"bend break\" + 0.000*\"head servant\" + 0.000*\"se ole\" + 0.000*\"eagle hawk\" + 0.000*\"little goat\" + 0.000*\"tir na\" + 0.000*\"say grasshopper\" + 0.000*\"se young\" + 0.000*\"water salt\"')])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf5_1, ldaMulticore_tf5_1_topics = LDAMulticore_model(vectorizer = tf5, doc_term = tf5_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf5_1, ldaMulticore_tf5_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bd4c5ad10>,\n",
       " [(0,\n",
       "   '0.001*\"white corn\" + 0.000*\"grandmother spider\" + 0.000*\"thou lt\" + 0.000*\"time cat\" + 0.000*\"beautiful field\" + 0.000*\"church yard\" + 0.000*\"climb sky\" + 0.000*\"man wolf\" + 0.000*\"hen home\" + 0.000*\"work thou\"'),\n",
       "  (1,\n",
       "   '0.001*\"bend break\" + 0.001*\"sea serpent\" + 0.001*\"big brother\" + 0.001*\"food cow\" + 0.000*\"stroke cut\" + 0.000*\"wintry day\" + 0.000*\"stoop stroke\" + 0.000*\"point eye\" + 0.000*\"fly cow\" + 0.000*\"say gratitude\"'),\n",
       "  (2,\n",
       "   '0.003*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"king lion\" + 0.001*\"little hahsie\" + 0.001*\"ou sculpat\" + 0.001*\"say musician\" + 0.001*\"oo oo\" + 0.001*\"se hahsie\" + 0.000*\"oom jakhal\" + 0.000*\"yellow dog\"'),\n",
       "  (3,\n",
       "   '0.001*\"hoo hoo\" + 0.001*\"mountain lion\" + 0.001*\"head servant\" + 0.000*\"think peasant\" + 0.000*\"manhattan island\" + 0.000*\"oom leeuw\" + 0.000*\"overtake throw\" + 0.000*\"sit bundle\" + 0.000*\"money belt\" + 0.000*\"old stick\"'),\n",
       "  (4,\n",
       "   '0.000*\"old dragon\" + 0.000*\"se ole\" + 0.000*\"man moon\" + 0.000*\"little goat\" + 0.000*\"shall walk\" + 0.000*\"se young\" + 0.000*\"se dey\" + 0.000*\"say stag\" + 0.000*\"way quiet\" + 0.000*\"love slay\"'),\n",
       "  (5,\n",
       "   '0.000*\"captain guard\" + 0.000*\"king sheep\" + 0.000*\"eagle hawk\" + 0.000*\"look balloon\" + 0.000*\"golden basin\" + 0.000*\"hoo hoo\" + 0.000*\"gray man\" + 0.000*\"say deer\" + 0.000*\"white owl\" + 0.000*\"long island\"'),\n",
       "  (6,\n",
       "   '0.001*\"yellow lily\" + 0.001*\"croak frog\" + 0.001*\"hide hill\" + 0.000*\"steal food\" + 0.000*\"wirreenun say\" + 0.000*\"spin spin\" + 0.000*\"buffalo head\" + 0.000*\"white moon\" + 0.000*\"blue mist\" + 0.000*\"holy place\"'),\n",
       "  (7,\n",
       "   '0.001*\"mice people\" + 0.001*\"brown sister\" + 0.000*\"yum yum\" + 0.000*\"hold bone\" + 0.000*\"sun ask\" + 0.000*\"say serpent\" + 0.000*\"white fat\" + 0.000*\"buffalo skull\" + 0.000*\"gah gah\" + 0.000*\"gour gah\"'),\n",
       "  (8,\n",
       "   '0.001*\"bush rat\" + 0.001*\"lady moon\" + 0.001*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"brown sister\" + 0.000*\"cat tail\" + 0.000*\"say grasshopper\" + 0.000*\"st anthony\" + 0.000*\"milk cat\"'),\n",
       "  (9,\n",
       "   '0.001*\"water demon\" + 0.000*\"let monkey\" + 0.000*\"make axe\" + 0.000*\"wood chopper\" + 0.000*\"certain wood\" + 0.000*\"cool sweet\" + 0.000*\"eye bit\" + 0.000*\"oak forest\" + 0.000*\"pride joy\" + 0.000*\"fine tree\"')])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf5_2, ldaMulticore_tf5_2_topics = LDAMulticore_model(vectorizer = tf5, doc_term = tf5_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf5_2, ldaMulticore_tf5_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb1e8c510>,\n",
       " [(0,\n",
       "   '0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"st anthony\" + 0.000*\"wirreenun say\" + 0.000*\"water jar\" + 0.000*\"poor brâhmaṇ\" + 0.000*\"mango fruit\" + 0.000*\"mango tree\" + 0.000*\"man wolf\"'),\n",
       "  (1,\n",
       "   '0.000*\"big brother\" + 0.000*\"brown sister\" + 0.000*\"little goat\" + 0.000*\"manhattan island\" + 0.000*\"long island\" + 0.000*\"yum yum\" + 0.000*\"golden basin\" + 0.000*\"st george\" + 0.000*\"end island\" + 0.000*\"white fat\"'),\n",
       "  (2,\n",
       "   '0.002*\"ou jackalse\" + 0.001*\"ou wolf\" + 0.000*\"hoo hoo\" + 0.000*\"se ou jackalse\" + 0.000*\"sea serpent\" + 0.000*\"head servant\" + 0.000*\"yellow dog\" + 0.000*\"old dragon\" + 0.000*\"food cow\" + 0.000*\"captain guard\"'),\n",
       "  (3,\n",
       "   '0.000*\"yellow lily\" + 0.000*\"bend break\" + 0.000*\"white corn\" + 0.000*\"grandmother spider\" + 0.000*\"shall walk\" + 0.000*\"brown sister\" + 0.000*\"church yard\" + 0.000*\"say grasshopper\" + 0.000*\"look balloon\" + 0.000*\"yes yes yes\"'),\n",
       "  (4,\n",
       "   '0.000*\"ruler heaven\" + 0.000*\"serpent king\" + 0.000*\"cat tail\" + 0.000*\"tir na\" + 0.000*\"milk cat\" + 0.000*\"let monkey\" + 0.000*\"monkey think\" + 0.000*\"stroke cut\" + 0.000*\"hold bone\" + 0.000*\"child death\"'),\n",
       "  (5,\n",
       "   '0.000*\"water demon\" + 0.000*\"thou lt\" + 0.000*\"croak frog\" + 0.000*\"house little house\" + 0.000*\"little house little\" + 0.000*\"little house live\" + 0.000*\"oom leeuw\" + 0.000*\"steal food\" + 0.000*\"live little house\" + 0.000*\"say stag\"'),\n",
       "  (6,\n",
       "   '0.000*\"little hahsie\" + 0.000*\"bush rat\" + 0.000*\"ou sculpat\" + 0.000*\"mountain lion\" + 0.000*\"lady moon\" + 0.000*\"king lion\" + 0.000*\"oo oo\" + 0.000*\"se hahsie\" + 0.000*\"man moon\" + 0.000*\"beautiful field\"'),\n",
       "  (7,\n",
       "   '0.000*\"say musician\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"spin spin\" + 0.000*\"se ole\" + 0.000*\"sun ask\" + 0.000*\"dat honey\" + 0.000*\"honey se\" + 0.000*\"foo foo\" + 0.000*\"gum tree\"')])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf6_1, ldaMulticore_tf6_1_topics = LDAMulticore_model(vectorizer = tf6, doc_term = tf6_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf6_1, ldaMulticore_tf6_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb1f1cf90>,\n",
       " [(0,\n",
       "   '0.001*\"yellow lily\" + 0.000*\"old dragon\" + 0.000*\"stroke cut\" + 0.000*\"stoop stroke\" + 0.000*\"wintry day\" + 0.000*\"cut serpent\" + 0.000*\"say gratitude\" + 0.000*\"slowly come\" + 0.000*\"child death\" + 0.000*\"seize axe\"'),\n",
       "  (1,\n",
       "   '0.001*\"water demon\" + 0.000*\"lady moon\" + 0.000*\"brown sister\" + 0.000*\"yellow dog\" + 0.000*\"think peasant\" + 0.000*\"yum yum\" + 0.000*\"say grasshopper\" + 0.000*\"white fat\" + 0.000*\"say deer\" + 0.000*\"time moon\"'),\n",
       "  (2,\n",
       "   '0.001*\"hoo hoo\" + 0.000*\"food cow\" + 0.000*\"brown sister\" + 0.000*\"beautiful field\" + 0.000*\"certain wood\" + 0.000*\"wood chopper\" + 0.000*\"make axe\" + 0.000*\"eye bit\" + 0.000*\"cool sweet\" + 0.000*\"oak forest\"'),\n",
       "  (3,\n",
       "   '0.001*\"mountain lion\" + 0.001*\"head servant\" + 0.000*\"white corn\" + 0.000*\"blue corn\" + 0.000*\"corn blue\" + 0.000*\"time cat\" + 0.000*\"eagle hawk\" + 0.000*\"manhattan island\" + 0.000*\"flask water\" + 0.000*\"say sparrow\"'),\n",
       "  (4,\n",
       "   '0.000*\"big brother\" + 0.000*\"se ole\" + 0.000*\"man moon\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"church yard\" + 0.000*\"climb sky\" + 0.000*\"dat honey\" + 0.000*\"hen home\" + 0.000*\"sky sister\"'),\n",
       "  (5,\n",
       "   '0.001*\"bush rat\" + 0.000*\"ou sculpat\" + 0.000*\"oo oo\" + 0.000*\"little hahsie\" + 0.000*\"oom jakhal\" + 0.000*\"king sheep\" + 0.000*\"oo oo oo\" + 0.000*\"serpent king\" + 0.000*\"little goat\" + 0.000*\"tell bush\"'),\n",
       "  (6,\n",
       "   '0.000*\"king lion\" + 0.000*\"thou lt\" + 0.000*\"ruler heaven\" + 0.000*\"sun ask\" + 0.000*\"cat tail\" + 0.000*\"little hahsie\" + 0.000*\"tir na\" + 0.000*\"let monkey\" + 0.000*\"monkey think\" + 0.000*\"spin spin\"'),\n",
       "  (7,\n",
       "   '0.001*\"sea serpent\" + 0.001*\"bend break\" + 0.000*\"pull sea\" + 0.000*\"look balloon\" + 0.000*\"hold bone\" + 0.000*\"water salt\" + 0.000*\"holy virgin\" + 0.000*\"love slay\" + 0.000*\"way quiet\" + 0.000*\"enemy love\"'),\n",
       "  (8,\n",
       "   '0.001*\"white corn\" + 0.001*\"say musician\" + 0.000*\"grandmother spider\" + 0.000*\"house little house\" + 0.000*\"little house little\" + 0.000*\"little house live\" + 0.000*\"croak frog\" + 0.000*\"live little house\" + 0.000*\"st anthony\" + 0.000*\"oom leeuw\"'),\n",
       "  (9,\n",
       "   '0.003*\"ou jackalse\" + 0.002*\"ou wolf\" + 0.001*\"se ou jackalse\" + 0.000*\"steal food\" + 0.000*\"wirreenun say\" + 0.000*\"se ou wolf\" + 0.000*\"white owl\" + 0.000*\"world beauty\" + 0.000*\"ou baviyàan\" + 0.000*\"grow tall tall\"')])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf6_2, ldaMulticore_tf6_2_topics = LDAMulticore_model(vectorizer = tf6, doc_term = tf6_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf6_2, ldaMulticore_tf6_2_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bb2103510>,\n",
       " [(0,\n",
       "   '0.001*\"brown sister\" + 0.000*\"yes baasje\" + 0.000*\"kill eat\" + 0.000*\"say farmer\" + 0.000*\"fat tail\" + 0.000*\"old brown\" + 0.000*\"fat say\" + 0.000*\"eat rat\" + 0.000*\"lot corn\" + 0.000*\"girl cat\"'),\n",
       "  (1,\n",
       "   '0.001*\"birch tree\" + 0.001*\"bend break\" + 0.001*\"lady moon\" + 0.000*\"little goat\" + 0.000*\"rich brother\" + 0.000*\"blow hard\" + 0.000*\"spin spin\" + 0.000*\"die die\" + 0.000*\"poor brother\" + 0.000*\"tree bend\"'),\n",
       "  (2,\n",
       "   '0.005*\"ou jackalse\" + 0.003*\"ou wolf\" + 0.002*\"se ou\" + 0.001*\"little hahsie\" + 0.001*\"king lion\" + 0.001*\"ou sculpat\" + 0.001*\"se hahsie\" + 0.001*\"old hendrik\" + 0.001*\"dat se\" + 0.000*\"eat fruit\"'),\n",
       "  (3,\n",
       "   '0.005*\"old man\" + 0.003*\"old woman\" + 0.003*\"young man\" + 0.001*\"long time\" + 0.001*\"say king\" + 0.001*\"poor man\" + 0.001*\"little boy\" + 0.001*\"run away\" + 0.001*\"say old\" + 0.001*\"little girl\"'),\n",
       "  (4,\n",
       "   '0.000*\"dead body\" + 0.000*\"climb sky\" + 0.000*\"remember message\" + 0.000*\"holy place\" + 0.000*\"message deliver\" + 0.000*\"time dog\" + 0.000*\"wood ashe\" + 0.000*\"carry food\" + 0.000*\"body leave\" + 0.000*\"body bury\"'),\n",
       "  (5,\n",
       "   '0.001*\"white feather\" + 0.001*\"little house\" + 0.001*\"mrs brien\" + 0.001*\"croak frog\" + 0.000*\"beautiful field\" + 0.000*\"cat tail\" + 0.000*\"think peasant\" + 0.000*\"cat cat\" + 0.000*\"milk cat\" + 0.000*\"hide hill\"'),\n",
       "  (6,\n",
       "   '0.000*\"hen home\" + 0.000*\"hunter wife\" + 0.000*\"day hunter\" + 0.000*\"hawk kill\" + 0.000*\"son sit\" + 0.000*\"eat cock\" + 0.000*\"hunter son\" + 0.000*\"native custom\" + 0.000*\"cock strut\" + 0.000*\"day hawk\"'),\n",
       "  (7,\n",
       "   '0.001*\"black fellow\" + 0.001*\"sea serpent\" + 0.001*\"head servant\" + 0.001*\"old woman\" + 0.001*\"little maid\" + 0.000*\"steal food\" + 0.000*\"eagle hawk\" + 0.000*\"tall tall\" + 0.000*\"build house\" + 0.000*\"dry grass\"'),\n",
       "  (8,\n",
       "   '0.001*\"oo oo\" + 0.001*\"oom jakhal\" + 0.001*\"manhattan island\" + 0.000*\"st anthony\" + 0.000*\"say peasant\" + 0.000*\"water jar\" + 0.000*\"st george\" + 0.000*\"good saint\" + 0.000*\"new amsterdam\" + 0.000*\"spuyten duyvil\"'),\n",
       "  (9,\n",
       "   '0.001*\"mountain lion\" + 0.000*\"ring master\" + 0.000*\"mouse gnaw\" + 0.000*\"catch mouse\" + 0.000*\"fetch ring\" + 0.000*\"gnaw hole\" + 0.000*\"water bag\" + 0.000*\"old wirreenun\" + 0.000*\"taste salt\" + 0.000*\"mouse say\"'),\n",
       "  (10,\n",
       "   '0.001*\"water demon\" + 0.001*\"little brother\" + 0.001*\"bush rat\" + 0.001*\"big brother\" + 0.000*\"boil water\" + 0.000*\"live forever\" + 0.000*\"come sky\" + 0.000*\"tell bush\" + 0.000*\"poison arrow\" + 0.000*\"young strong\"'),\n",
       "  (11,\n",
       "   '0.001*\"say lad\" + 0.001*\"day say\" + 0.001*\"war eagle\" + 0.001*\"white corn\" + 0.001*\"young brother\" + 0.001*\"people say\" + 0.001*\"golden ducat\" + 0.001*\"blue corn\" + 0.001*\"corn blue\" + 0.001*\"food cow\"'),\n",
       "  (12,\n",
       "   '0.001*\"yellow dog\" + 0.000*\"spot dog\" + 0.000*\"water melon\" + 0.000*\"tail dog\" + 0.000*\"dinner party\" + 0.000*\"say serpent\" + 0.000*\"black dog\" + 0.000*\"hire servant\" + 0.000*\"white dog\" + 0.000*\"mud bank\"'),\n",
       "  (13,\n",
       "   '0.001*\"yellow lily\" + 0.001*\"se ole\" + 0.001*\"thou lt\" + 0.001*\"say moon\" + 0.001*\"dat honey\" + 0.001*\"man moon\" + 0.000*\"se young\" + 0.000*\"say grasshopper\" + 0.000*\"ole missis\" + 0.000*\"stoop stroke\"'),\n",
       "  (14,\n",
       "   '0.001*\"brown sister\" + 0.001*\"ruler heaven\" + 0.001*\"time cat\" + 0.001*\"wood chopper\" + 0.000*\"cool sweet\" + 0.000*\"make axe\" + 0.000*\"eye bit\" + 0.000*\"certain wood\" + 0.000*\"serpent king\" + 0.000*\"yum yum\"'),\n",
       "  (15,\n",
       "   '0.001*\"water life\" + 0.001*\"golden haired\" + 0.000*\"drinking horn\" + 0.000*\"mother sheep\" + 0.000*\"animal bird\" + 0.000*\"water death\" + 0.000*\"ma ui\" + 0.000*\"bring food\" + 0.000*\"carry load\" + 0.000*\"foo foo\"'),\n",
       "  (16,\n",
       "   '0.001*\"say musician\" + 0.001*\"great spirit\" + 0.000*\"say virgin\" + 0.000*\"enemy love\" + 0.000*\"come pursuit\" + 0.000*\"curse say\" + 0.000*\"way quiet\" + 0.000*\"love slay\" + 0.000*\"holy virgin\" + 0.000*\"come lodge\"'),\n",
       "  (17,\n",
       "   '0.001*\"main street\" + 0.001*\"little bird\" + 0.000*\"milk white\" + 0.000*\"head chief\" + 0.000*\"brother law\" + 0.000*\"look balloon\" + 0.000*\"gray man\" + 0.000*\"cream puff\" + 0.000*\"dusty road\" + 0.000*\"holy mother\"'),\n",
       "  (18,\n",
       "   '0.001*\"king sheep\" + 0.000*\"blow away\" + 0.000*\"christ child\" + 0.000*\"captain guard\" + 0.000*\"time farmer\" + 0.000*\"farmer cross\" + 0.000*\"door pity\" + 0.000*\"farmer greatly\" + 0.000*\"circle strike\" + 0.000*\"fate soon\"'),\n",
       "  (19,\n",
       "   '0.001*\"white corn\" + 0.001*\"grandmother spider\" + 0.001*\"little lamb\" + 0.001*\"st peter\" + 0.001*\"old farmer\" + 0.000*\"church yard\" + 0.000*\"pull sea\" + 0.000*\"rat mouse\" + 0.000*\"christ child\" + 0.000*\"man wolf\"')])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf1_6, ldaMulticore_tf1_6_topics = LDAMulticore_model(vectorizer = tf1, doc_term = tf1_matrix, \n",
    "                                                               num_topics = 20, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf1_6, ldaMulticore_tf1_6_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6bddb7f1d0>,\n",
       " [(0,\n",
       "   '0.005*\"coyote\" + 0.004*\"chan\" + 0.003*\"violette\" + 0.003*\"ourson\" + 0.002*\"arthur\" + 0.002*\"rosalie\" + 0.002*\"seer\" + 0.002*\"li\" + 0.002*\"ma\" + 0.001*\"ellen\"'),\n",
       "  (1,\n",
       "   '0.004*\"godfather\" + 0.003*\"iktomi\" + 0.003*\"brahman\" + 0.002*\"outa\" + 0.002*\"tablecloth\" + 0.002*\"carabao\" + 0.002*\"jakhal\" + 0.002*\"oom\" + 0.002*\"kangaroo\" + 0.002*\"sculptor\"'),\n",
       "  (2,\n",
       "   '0.003*\"rosette\" + 0.002*\"balloon\" + 0.002*\"banana\" + 0.002*\"peddler\" + 0.002*\"hoo\" + 0.002*\"merman\" + 0.002*\"simon\" + 0.001*\"security\" + 0.001*\"skyscraper\" + 0.001*\"redbreast\"'),\n",
       "  (3,\n",
       "   '0.003*\"dat\" + 0.003*\"sexton\" + 0.003*\"ou\" + 0.003*\"se\" + 0.002*\"johnny\" + 0.002*\"juan\" + 0.002*\"piccaninny\" + 0.002*\"giufà\" + 0.002*\"ole\" + 0.002*\"brâhmiṇ\"'),\n",
       "  (4,\n",
       "   '0.004*\"sigurd\" + 0.003*\"hedgehog\" + 0.003*\"caliph\" + 0.002*\"pope\" + 0.002*\"sindbad\" + 0.002*\"bailiff\" + 0.002*\"grethel\" + 0.002*\"anthony\" + 0.002*\"sequin\" + 0.002*\"florin\"'),\n",
       "  (5,\n",
       "   '0.004*\"tsarevich\" + 0.004*\"ju\" + 0.002*\"tsarevna\" + 0.002*\"archer\" + 0.002*\"burner\" + 0.002*\"mannikin\" + 0.002*\"ama\" + 0.002*\"kung\" + 0.002*\"gabriel\" + 0.002*\"jogi\"'),\n",
       "  (6,\n",
       "   '0.002*\"raja\" + 0.002*\"blondine\" + 0.002*\"dervish\" + 0.002*\"padishah\" + 0.001*\"rasâlu\" + 0.001*\"vizier\" + 0.001*\"rajah\" + 0.001*\"gazelle\" + 0.001*\"theseus\" + 0.001*\"brâhmaṇ\"'),\n",
       "  (7,\n",
       "   '0.005*\"perseus\" + 0.003*\"tzar\" + 0.003*\"maroosia\" + 0.002*\"badger\" + 0.002*\"squash\" + 0.002*\"czar\" + 0.002*\"betel\" + 0.002*\"aponibolinayen\" + 0.002*\"michael\" + 0.002*\"aponitolau\"')])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf7_1, ldaMulticore_tf7_1_topics = LDAMulticore_model(vectorizer = tf7, doc_term = tf7_matrix, \n",
    "                                                               num_topics = 8, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf7_1, ldaMulticore_tf7_1_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gensim.models.ldamulticore.LdaMulticore at 0x7f6c106b9a90>,\n",
       " [(0,\n",
       "   '0.001*\"ou wolf\" + 0.000*\"yang\" + 0.000*\"sculptor\" + 0.000*\"old farmer\" + 0.000*\"buttonhole\" + 0.000*\"scarf\" + 0.000*\"kashim\" + 0.000*\"ane\" + 0.000*\"climb sky\" + 0.000*\"spin spin\"'),\n",
       "  (1,\n",
       "   '0.000*\"oerlang\" + 0.000*\"cow\" + 0.000*\"jakhal\" + 0.000*\"little house\" + 0.000*\"oo\" + 0.000*\"food cow\" + 0.000*\"jupiter\" + 0.000*\"croak frog\" + 0.000*\"tante\" + 0.000*\"jove\"'),\n",
       "  (2,\n",
       "   '0.001*\"weedah\" + 0.000*\"virgin\" + 0.000*\"lady moon\" + 0.000*\"pepper\" + 0.000*\"outa\" + 0.000*\"yellow dog\" + 0.000*\"fiend\" + 0.000*\"little lamb\" + 0.000*\"compound\" + 0.000*\"perseus\"'),\n",
       "  (3,\n",
       "   '0.001*\"dick\" + 0.001*\"mohawk\" + 0.000*\"yellow lily\" + 0.000*\"sprite\" + 0.000*\"humpie\" + 0.000*\"steal food\" + 0.000*\"pope\" + 0.000*\"tall tall\" + 0.000*\"wood chopper\" + 0.000*\"certain wood\"'),\n",
       "  (4,\n",
       "   '0.001*\"anthony\" + 0.000*\"jakhal\" + 0.000*\"bush rat\" + 0.000*\"pedro\" + 0.000*\"head servant\" + 0.000*\"curlew\" + 0.000*\"cheiron\" + 0.000*\"pottage\" + 0.000*\"pocket handkerchief\" + 0.000*\"outa\"'),\n",
       "  (5,\n",
       "   '0.001*\"yanechek\" + 0.001*\"antelope\" + 0.000*\"oni\" + 0.000*\"berry\" + 0.000*\"raiko\" + 0.000*\"animal bird\" + 0.000*\"worm\" + 0.000*\"driver\" + 0.000*\"eyo\" + 0.000*\"hold bone\"'),\n",
       "  (6,\n",
       "   '0.001*\"meamei\" + 0.001*\"leeuw\" + 0.000*\"banana\" + 0.000*\"white corn\" + 0.000*\"outa\" + 0.000*\"daen\" + 0.000*\"grandmother spider\" + 0.000*\"virgin\" + 0.000*\"golden ducat\" + 0.000*\"peddler\"'),\n",
       "  (7,\n",
       "   '0.004*\"say\" + 0.003*\"come\" + 0.002*\"man\" + 0.002*\"king\" + 0.002*\"little\" + 0.002*\"old\" + 0.002*\"make\" + 0.002*\"day\" + 0.001*\"tell\" + 0.001*\"time\"'),\n",
       "  (8,\n",
       "   '0.001*\"oisin\" + 0.000*\"sea serpent\" + 0.000*\"main street\" + 0.000*\"hyena\" + 0.000*\"woodsman\" + 0.000*\"bend break\" + 0.000*\"jakhal\" + 0.000*\"yum\" + 0.000*\"sparrow\" + 0.000*\"birch tree\"'),\n",
       "  (9,\n",
       "   '0.001*\"grasshopper\" + 0.001*\"hoo\" + 0.001*\"balloon\" + 0.001*\"ang\" + 0.000*\"boggart\" + 0.000*\"hoo hoo\" + 0.000*\"yang\" + 0.000*\"creator\" + 0.000*\"white corn\" + 0.000*\"stag\"')])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaMulticore_tf8_1, ldaMulticore_tf8_1_topics = LDAMulticore_model(vectorizer = tf8, doc_term = tf8_matrix, \n",
    "                                                               num_topics = 10, passes = 100, chunksize = 500, workers = 6)\n",
    "ldaMulticore_tf8_1, ldaMulticore_tf8_1_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some observations from LDA and LSA models\n",
    "- CountVectorizer is not good at differentiating topics in general.\n",
    "- TFIDF with bigram is better than unigram, trigram or bigram&trigram.\n",
    "- Topics make more sense then topic_num >= 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The best selected LDA model is used for recommender system**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m54",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m54"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
